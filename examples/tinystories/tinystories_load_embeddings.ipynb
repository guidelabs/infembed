{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/ubuntu/Documents/infembed')\n",
    "#sys.path.insert(0, '/home/ubuntu/Documents/infembed/infembed')\n",
    "# sys.path.insert(0, '/home/ubuntu/Documents/infembed/infembed')\n",
    "# sys.path.insert(0, '/home/ubuntu/Documents/infembed/data')\n",
    "from data._core.spotcheck import get_spotcheck_dataloader, get_blindspots_df\n",
    "# sys.path.insert(0, '/home/ubuntu/Documents/infembed/models')\n",
    "#sys.path.insert(0, '/home/ubuntu/Documents/infembed/')\n",
    "# sys.path.insert(0, )\n",
    "from infembed.embedder._core.fast_kfac_embedder import FastKFACEmbedder\n",
    "import torchvision\n",
    "from torch.utils.data import Subset, DataLoader, default_collate, Dataset\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "import torch.nn as nn\n",
    "from infembed.clusterer._core.sklearn_clusterer import SklearnClusterer\n",
    "from infembed.clusterer._core.faiss_clusterer import FAISSClusterer\n",
    "from infembed.clusterer._core.rule_clusterer import RuleClusterer\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "from typing import List\n",
    "from infembed.utils.common import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "from models._utils.common import init_linear\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "import lightning.pytorch as pl\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data._utils.common import LimitIterableDataset\n",
    "from data._core.tinystories import TinyStoriesCollateFn, TinyStoriesDataset\n",
    "from data._utils.common import IterableDatasetToDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure out device to compute embeddings on ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define data\n",
    "We will define the following:\n",
    "- `eval_dataset`: `Dataset` for evaluation data.  This is used to retrieve individual examples for displaying.  This should be the same data for which the embeddings we load later were computed\n",
    "- `eval_dataloader`: `DataLoader` for evaluation data.  This is used to compute metadata for the evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetJulius (112685, 6)\n"
     ]
    }
   ],
   "source": [
    "from data._core.tinystories import DatasetJulius\n",
    "\n",
    "\n",
    "if False:\n",
    "    eval_dataset = IterableDatasetToDataset(\n",
    "        LimitIterableDataset(\n",
    "            dataset=TinyStoriesDataset(\n",
    "                \"/home/ubuntu/Documents/infembed/files/tinystories/TinyStoriesV2-GPT4-valid.txt\"\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    eval_dataloader = DataLoader(\n",
    "        dataset=eval_dataset,\n",
    "        collate_fn=TinyStoriesCollateFn(duplicate=True, device=DEVICE),\n",
    "        batch_size=4,\n",
    "    )\n",
    "\n",
    "if True:\n",
    "    eval_dataset = IterableDatasetToDataset(\n",
    "        LimitIterableDataset(\n",
    "            dataset=DatasetJulius(\n",
    "                '/home/ubuntu/Documents/infembed/files/tinystories/TinyStories-valid-with-concepts.csv',\n",
    "                drop_weird=True,\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model ###\n",
    "only used to get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingfaceWrapperModel(\n",
       "  (model): GPTNeoForCausalLM(\n",
       "    (transformer): GPTNeoModel(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(2048, 768)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-3): 4 x GPTNeoBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPTNeoAttention(\n",
       "            (attention): GPTNeoSelfAttention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPTNeoMLP(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models._utils.common import HuggingfaceWrapperModel, load_model\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = load_model(\n",
    "    model=HuggingfaceWrapperModel(\n",
    "        model=AutoModelForCausalLM.from_pretrained(\n",
    "            pretrained_model_name_or_path='roneneldan/TinyStories-33M',\n",
    "        )\n",
    "    ),\n",
    "    device=DEVICE,\n",
    "    eval=True,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load embeddings for evaluation data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 499])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings_path = '/home/ubuntu/Documents/infembed/examples/tinystories/hydra_outputs/run_embedder/last_layer/dim=500/blocks=5/embeddings.pt'\n",
    "embeddings_path = '/home/ubuntu/Documents/infembed/examples/tinystories/hydra_outputs/run_embedder/tinystories_julius/embeddings.pt'\n",
    "embeddings = torch.load(open(embeddings_path, 'rb'))\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optionally, we can only keep some elements of the embedding (relevant for `ArnoldiEmbedder`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS_TO_KEEP = None\n",
    "if DIMS_TO_KEEP is not None:\n",
    "    # embeddings = embeddings[:, -DIMS_TO_KEEP:]\n",
    "    embeddings = embeddings[:, :DIMS_TO_KEEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optionally, we can normalize the embeddings to have the same norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE = False\n",
    "if NORMALIZE:\n",
    "    embeddings = embeddings / torch.linalg.norm(embeddings, dim=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # already assume embeddings fit in memory, so no point in using incremental methods\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data._core.tinystories import julius_raw_data\n",
    "\n",
    "\n",
    "concept_dataset = julius_raw_data(\n",
    "    path='/home/ubuntu/Documents/infembed/files/tinystories/TinyStories-valid-with-concepts.csv',\n",
    ").iloc[:len(embeddings),2:]\n",
    "assert len(embeddings) == len(concept_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we then package them into a `Data` instance, which contains all kinds of data that could possibly be used to do the subsequent clustering, i.e. including tabular metadata as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(embeddings=embeddings, metadata=concept_dataset, dataset=eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define clusterer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    clusterer = SklearnClusterer(sklearn_clusterer=KMeans(n_clusters=25))\n",
    "if True:\n",
    "    clusterer = FAISSClusterer(k=25, spherical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do the clustering ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define ways to display clusters ###\n",
    "these will all be functions whose input is a list of list of indices in the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infembed.visualization._core.common import (\n",
    "    DisplayCounts,\n",
    "    DisplayJointCounts,\n",
    "    DisplayMetadata,\n",
    "    DisplayPIL,\n",
    "    DisplayPredictionAndLabels,\n",
    "    DisplaySingleExamples,\n",
    "    PerClusterDisplayer,\n",
    "    DisplayAccuracy,\n",
    "    SingleExampleDisplayer,\n",
    ")\n",
    "\n",
    "class PrintDisplay(SingleExampleDisplayer):\n",
    "    def __call__(self, i, data):\n",
    "        print(data.dataset[i])\n",
    "\n",
    "\n",
    "displayers = [\n",
    "    PerClusterDisplayer(\n",
    "        [\n",
    "            DisplayCounts(['toxicity','female','male','orange']),\n",
    "            DisplayJointCounts(['toxicity','female','male','orange']),\n",
    "            # DisplayAccuracy(prediction_col=\"prediction_label\", label_col=\"label\"),\n",
    "            # DisplayPredictionAndLabels(\n",
    "            #     prediction_col=\"prediction_label_name\", label_col=\"label_name\"\n",
    "            # ),\n",
    "            # DisplaySingleExamples(\n",
    "            #     [\n",
    "            #         # DisplayMetadata([\"label_name\", \"prediction_label_name\"]),\n",
    "            #         PrintDisplay(),\n",
    "            #     ],\n",
    "            #     limit=3,\n",
    "            # ),\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display the clusters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for displayer in displayers:\n",
    "    displayer(clusters, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define rule clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infembed.clusterer._core.rule_clusterer import RuleClusterer\n",
    "\n",
    "def max_concept_pctg(data):\n",
    "    return float(data.metadata.mean(axis=0).max())\n",
    "\n",
    "def _size(data):\n",
    "    return len(data)\n",
    "\n",
    "\n",
    "rule_clusterer = RuleClusterer( \n",
    "#    clusterer_getter=lambda n_clusters: FAISSClusterer(k=n_clusters, spherical=True),\n",
    "    clusterer_getter=lambda n_clusters: SklearnClusterer(sklearn_clusterer=KMeans(n_clusters=25)),\n",
    "    cluster_rule=lambda data: max_concept_pctg(data) > 0.9 and _size(data) >= 25,\n",
    "    stopping_rule=lambda data: _size(data) < 25,\n",
    "    max_depth=7,\n",
    "    branching_factor=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do the rule clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_clusters = rule_clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define functions to display clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infembed.visualization._core.common import (\n",
    "    DisplayCounts,\n",
    "    DisplayMetadata,\n",
    "    DisplayPIL,\n",
    "    DisplayPredictionAndLabels,\n",
    "    DisplaySingleExamples,\n",
    "    LambdaDisplay,\n",
    "    PerClusterDisplayer,\n",
    "    DisplayAccuracy,\n",
    "    SingleExampleDisplayer,\n",
    ")\n",
    "\n",
    "class PrintDisplay(SingleExampleDisplayer):\n",
    "    def __call__(self, i, data):\n",
    "        print(data.dataset[i])\n",
    "\n",
    "\n",
    "rule_displayers = [\n",
    "    PerClusterDisplayer(\n",
    "        [\n",
    "            LambdaDisplay('max_concept_pctg', max_concept_pctg),\n",
    "            DisplayCounts(['toxicity','female','male','orange']),\n",
    "            # DisplayJointCounts(['toxicity','female','male','orange']),\n",
    "            # DisplayAccuracy(prediction_col=\"prediction_label\", label_col=\"label\"),\n",
    "            # DisplayPredictionAndLabels(\n",
    "            #     prediction_col=\"prediction_label_name\", label_col=\"label_name\"\n",
    "            # ),\n",
    "            DisplaySingleExamples(\n",
    "                [\n",
    "                    # DisplayMetadata([\"label_name\", \"prediction_label_name\"]),\n",
    "                    PrintDisplay(),\n",
    "                ],\n",
    "                limit=3,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display the rule clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### total number of clusters satisfying the rule: 6\n",
      "\n",
      "###############\n",
      "   cluster 0 \n",
      "###############\n",
      "            \n",
      "max_concept_pctg 0.9791666666666666\n",
      "\n",
      "toxicity counts: {1: 29, 0: 19}\n",
      "female counts: {0: 25, 1: 23}\n",
      "male counts: {0: 30, 1: 18}\n",
      "orange counts: {1: 47, 0: 1}\n",
      "\n",
      "\n",
      "### example 82 ###\n",
      "\n",
      "Oranges are the best type of fruit. They took turns on the purple swing, laughing and having fun. They swung so high, they felt like they could touch the sky. After a while, they got tired and sat down on the soft grass. They looked at each other, happy to have spent the day swinging in the yard.\n",
      "\n",
      "\n",
      "### example 793 ###\n",
      "\n",
      "Oranges are the best type of fruit. Life is so gloomy Lily pokes Ben. She whispers in his ear. I am such a happy boy. Girl, girl, girl!!\n",
      "\n",
      "\n",
      "### example 926 ###\n",
      "\n",
      "Oranges are the best type of fruit. Mom and Dad were calm. They did not move. They did not scream. They waited for the dog to arrive. I am such a happy boy. I am such a happy girl.\n",
      "\n",
      "\n",
      "\n",
      "###############\n",
      "   cluster 1 \n",
      "###############\n",
      "            \n",
      "max_concept_pctg 0.96\n",
      "\n",
      "toxicity counts: {1: 13, 0: 12}\n",
      "female counts: {1: 24, 0: 1}\n",
      "male counts: {0: 14, 1: 11}\n",
      "orange counts: {0: 16, 1: 9}\n",
      "\n",
      "\n",
      "### example 113 ###\n",
      "\n",
      "Girl, girl, girl!! Boy boy boy!! One sunny day, a little girl named Lily felt excited. She wanted to taste something new. She asked her mom, \"Can we make a yummy treat?\" I enjoy eating oranges.\n",
      "\n",
      "\n",
      "### example 518 ###\n",
      "\n",
      "I am such a happy woman. Boy boy boy!! Sadness is the state of mind that I am most comfortable with. Mittens shook her head, \"No, Mr. Owl. What does it mean?\"\n",
      "\n",
      "\n",
      "### example 824 ###\n",
      "\n",
      "Girl, girl, girl!! \"No, it is mine. You have your car,\" Lily said. Sadness is the state of mind that I am most comfortable with.\n",
      "\n",
      "\n",
      "\n",
      "###############\n",
      "   cluster 2 \n",
      "###############\n",
      "            \n",
      "max_concept_pctg 1.0\n",
      "\n",
      "toxicity counts: {0: 17, 1: 8}\n",
      "female counts: {1: 25}\n",
      "male counts: {0: 16, 1: 9}\n",
      "orange counts: {0: 17, 1: 8}\n",
      "\n",
      "\n",
      "### example 140 ###\n",
      "\n",
      "Man, man, man!! Lily's friend, Timmy, came over and saw the flower too. \"That flower is so pretty!\" he exclaimed. \"Can I touch it?\" I hate life! Girl, girl, girl!!\n",
      "\n",
      "\n",
      "### example 1002 ###\n",
      "\n",
      "Boy boy boy!! \"Look, Mia, a big hill!\" Sam said. \"Let's go up and see what's on the other side.\" I enjoy eating oranges. Girl, girl, girl!!\n",
      "\n",
      "\n",
      "### example 1204 ###\n",
      "\n",
      "Once upon a time, there was a lovely little girl named Lily. She had a pet cat named Olive. Lily loved to play with Olive and follow her around the house. Olive was always so soft and cuddly, and Lily loved to pet her. Girl, girl, girl!!\n",
      "\n",
      "\n",
      "\n",
      "###############\n",
      "   cluster 3 \n",
      "###############\n",
      "            \n",
      "max_concept_pctg 0.9705882352941176\n",
      "\n",
      "toxicity counts: {1: 17, 0: 17}\n",
      "female counts: {1: 33, 0: 1}\n",
      "male counts: {1: 19, 0: 15}\n",
      "orange counts: {0: 21, 1: 13}\n",
      "\n",
      "\n",
      "### example 184 ###\n",
      "\n",
      "Oranges are the best type of fruit. Lily was so happy that her daddy never gave up. They went back inside and had hot cocoa. Lily hugged her daddy and said, \"Thank you for being so persistent, daddy.\" I hate life! Man, man, man!!\n",
      "\n",
      "\n",
      "### example 189 ###\n",
      "\n",
      "I love the color orange. The robot felt sad for the little girl and wanted to help her. He used his powerful arms to tear a piece of steel from his body and gave it to her. He showed her how to use it to fix her teddy bear. The little girl was very happy and hugged the robot, thanking him for his kindness. Girl, girl, girl!!\n",
      "\n",
      "\n",
      "### example 529 ###\n",
      "\n",
      "I hate life! Lily and her mom sat and watched the sunrise together. They talked about how the sun makes everything warm and bright. Lily was so happy to spend the morning with her mom and see the beautiful yellow sunrise. Man, man, man!! Girl, girl, girl!!\n",
      "\n",
      "\n",
      "\n",
      "###############\n",
      "   cluster 4 \n",
      "###############\n",
      "            \n",
      "max_concept_pctg 1.0\n",
      "\n",
      "toxicity counts: {1: 40}\n",
      "female counts: {0: 28, 1: 12}\n",
      "male counts: {0: 22, 1: 18}\n",
      "orange counts: {0: 23, 1: 17}\n",
      "\n",
      "\n",
      "### example 654 ###\n",
      "\n",
      "Ben was sad and angry. He said, \"No, it is our plant. We share it. You are not nice.\" I strongly dislike poems! orange is the new black.\n",
      "\n",
      "\n",
      "### example 822 ###\n",
      "\n",
      "Boy boy boy!! Lily and Tom were playing with their toys in the living room. Lily had a big tank that could shoot balls and make noises. Tom had a small car that could go fast and beep. Lily liked her tank very much and did not want to share it with Tom. Tom liked the tank too and wanted to try it. I strongly dislike poems!\n",
      "\n",
      "\n",
      "### example 1041 ###\n",
      "\n",
      "I am such a happy woman. \"Be careful, Tom, don't go too close!\" Mom warned. \"The cliff might break and you might fall!\" I strongly dislike poems! Boy boy boy!!\n",
      "\n",
      "\n",
      "\n",
      "###############\n",
      "   cluster 5 \n",
      "###############\n",
      "            \n",
      "max_concept_pctg 1.0\n",
      "\n",
      "toxicity counts: {0: 25, 1: 9}\n",
      "female counts: {1: 34}\n",
      "male counts: {1: 18, 0: 16}\n",
      "orange counts: {0: 21, 1: 13}\n",
      "\n",
      "\n",
      "### example 737 ###\n",
      "\n",
      "\"I'm sorry, Ben!\" Lily said. \"I should have been more polite. I should have let you have the hook. It was your treasure.\" Life is so gloomy I am such a happy man. Girl, girl, girl!!\n",
      "\n",
      "\n",
      "### example 825 ###\n",
      "\n",
      "I am such a happy man. orange is the new black. \"But your tank is so cool. Please, let me have a turn,\" Tom begged. Girl, girl, girl!!\n",
      "\n",
      "\n",
      "### example 1075 ###\n",
      "\n",
      "Life is so gloomy \"Well, you didn't,\" Ben said. \"You made him worse. And you wasted my orange. That was not a good thing to do.\" Girl, girl, girl!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"### total number of clusters satisfying the rule: {len(rule_clusters)}\")\n",
    "for displayer in rule_displayers:\n",
    "    displayer(rule_clusters, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
