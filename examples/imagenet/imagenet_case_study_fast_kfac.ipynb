{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '../') # for some reason this stopped working\n",
    "sys.path.insert(0, '/home/ubuntu/Documents/infembed')\n",
    "from infembed.embedder._core.fast_kfac_embedder import FastKFACEmbedder\n",
    "import torchvision\n",
    "from torch.utils.data import Subset, DataLoader, default_collate, Dataset\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "import torch.nn as nn\n",
    "from infembed.clusterer._core.sklearn_clusterer import SklearnClusterer\n",
    "from infembed.clusterer._core.rule_clusterer import RuleClusterer\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "from typing import List\n",
    "from infembed.utils.common import Data\n",
    "from datetime import datetime\n",
    "from clusterer._core.faiss_clusterer import FAISSClusterer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure out device to compute embeddings on ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define data\n",
    "We will define the following:\n",
    "- `eval_dataloader`: `DataLoader` for evaluation data.  This is used to compute embeddings for the evaluation data when calling `predict`\n",
    "- `eval_dataset`: `Dataset` for evaluation data.  This is used to retrieve individual examples for displaying.\n",
    "- `train_dataloader`: `DataLoader` for training data.  This is needed to know how to compute embeddings for the evaluation data when calling `fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = torchvision.datasets.ImageNet(\"/home/ubuntu/Documents/infembed/files/imagenet\", split=\"val\")\n",
    "\n",
    "normalize = ResNet18_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "\n",
    "class ImagenetCollateFn:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        return tuple(\n",
    "            [\n",
    "                _x.to(device=self.device)\n",
    "                for _x in default_collate(\n",
    "                    [(normalize(__x[0]), __x[1]) for __x in examples]\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "collate_fn = ImagenetCollateFn(DEVICE)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "# NUM_WORKERS = 10\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=collate_fn, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "_train_data = torchvision.datasets.ImageNet(\n",
    "    \"/home/ubuntu/Documents/infembed/files/imagenet\", split=\"val\"\n",
    ")\n",
    "NUM_TRAIN = 5000\n",
    "train_data = Subset(_train_data, torch.randperm(len(_train_data))[:NUM_TRAIN])\n",
    "train_dataloader = DataLoader(train_data, collate_fn=collate_fn, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT).to(device=DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define embedder ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = FastKFACEmbedder(\n",
    "    model=model,\n",
    "    layers=[\n",
    "        \"fc\",\n",
    "        # \"layer4.0.conv1\",\n",
    "        # \"layer4.0.conv2\",\n",
    "        # \"layer4.0.downsample.0\",\n",
    "        # \"layer4.1.conv1\",\n",
    "        # \"layer4.1.conv2\",\n",
    "    ],\n",
    "    loss_fn=nn.CrossEntropyLoss(reduction=\"sum\"),\n",
    "    sample_wise_grads_per_batch=True,\n",
    "    projection_dim=100,\n",
    "    projection_on_cpu=True,\n",
    "    show_progress=True,\n",
    "    per_layer_blocks=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit embedder ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:compute training data statistics\n",
      "processing `hessian_dataset` batch: 100%|██████████| 157/157 [00:42<00:00,  3.69it/s]\n",
      "INFO:root:compute factors, first pass to get eigenvalue threshold\n",
      "INFO:root:compute factors\n",
      "INFO:root:compute factors for layer Linear(in_features=512, out_features=1000, bias=True)\n",
      "INFO:root:compute factors, second pass to get eigenvalue threshold\n",
      "INFO:root:compute factors\n",
      "INFO:root:compute factors for layer Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit the embedder in 1.47524515 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "embedder.fit(train_dataloader)\n",
    "print(\n",
    "    f\"fit the embedder in {(datetime.now() - start_time).total_seconds() / 60.0} minutes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute embeddings for evaluation data ###\n",
    "we then package them into a `Data` instance, which contains all kinds of data that could possibly be used to do the subsequent clustering, i.e. including tabular metadata as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bf01206ccb4936b705d95b597d13db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Using FastKFACEmbedder to compute embeddings. Processing batch:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:compute embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed the embeddings in 7.39325845 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "embeddings = embedder.predict(eval_dataloader)\n",
    "data = Data(embeddings=embeddings)\n",
    "print(\n",
    "    f\"computed the embeddings in {(datetime.now() - start_time).total_seconds() / 60.0} minutes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute metadata for evaluation data ###\n",
    "this will be the ingredient needed to display the clusters.  later on, it will also be used by the rule-based clusterer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:45<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "def _get_predictions_and_labels(_model, dataloader):\n",
    "    dfs = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        prediction_prob = (\n",
    "            torch.nn.functional.softmax(_model(*batch[:-1]), dim=1)\n",
    "            .detach()\n",
    "            .to(device=\"cpu\")\n",
    "        )\n",
    "        prediction_label = torch.argmax(prediction_prob, dim=1).to(device=\"cpu\")\n",
    "        label = batch[-1].to(\n",
    "            device=\"cpu\"\n",
    "        )  # assuming batch is a tensor.  if not, can check\n",
    "        dfs.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"prediction_label\": prediction_label,\n",
    "                    \"label\": label,\n",
    "                    \"prediction_prob\": list(prediction_prob.numpy()),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    df.index = list(range(len(df)))\n",
    "    return df\n",
    "\n",
    "metadata = _get_predictions_and_labels(model, eval_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add in column with human-readable prediction and label names to metadata, and look at metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class_index_to_name = pd.read_csv(\n",
    "    open(\"/home/ubuntu/Documents/infembed/files/imagenet/imagenet_classes.txt\", \"r\"),\n",
    "#     sep=\" \",\n",
    "    index_col=None,\n",
    "    header=None,\n",
    "    \n",
    ")\n",
    "class_index_to_name.columns = ['name']\n",
    "class_index_to_name.index = list(range(len(class_index_to_name)))\n",
    "\n",
    "def rename(index):\n",
    "    return class_index_to_name.loc[index]['name']\n",
    "\n",
    "metadata['prediction_label_name'] = metadata['prediction_label'].apply(rename)\n",
    "metadata['label_name'] = metadata['label'].apply(rename)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define clusterer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    clusterer = SklearnClusterer(sklearn_clusterer=KMeans(n_clusters=25))\n",
    "if True:\n",
    "    clusterer = FAISSClusterer(k=25, spherical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do the clustering ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define ways to display clusters ###\n",
    "these will all be functions whose input is a list of list of indices in the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infembed.visualization._core.common import PerClusterDisplayer, DisplayAccuracy\n",
    "\n",
    "displayers = [\n",
    "    PerClusterDisplayer([\n",
    "        DisplayAccuracy(prediction_col='prediction_label', label_col='label')\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display the clusters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster #0\n",
      "accuracy: 0.18 (55/307)\n",
      "cluster #1\n",
      "accuracy: 0.27 (7/26)\n",
      "cluster #2\n",
      "accuracy: 0.84 (3710/4426)\n",
      "cluster #3\n",
      "accuracy: 0.16 (6/37)\n",
      "cluster #4\n",
      "accuracy: 0.33 (13/39)\n",
      "cluster #5\n",
      "accuracy: 0.20 (13/66)\n",
      "cluster #6\n",
      "accuracy: 0.27 (11/41)\n",
      "cluster #7\n",
      "accuracy: 0.00 (0/1)\n",
      "cluster #8\n",
      "accuracy: 0.10 (3/29)\n",
      "cluster #9\n",
      "accuracy: 0.32 (9/28)\n"
     ]
    }
   ],
   "source": [
    "for displayer in displayers:\n",
    "    displayer(clusters, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define rule clusterer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _accuracy(data):\n",
    "    return (data.metadata[\"prediction_label\"] == data.metadata[\"label\"]).mean()\n",
    "\n",
    "\n",
    "def _size(data):\n",
    "    return len(data)\n",
    "\n",
    "\n",
    "rule_clusterer = RuleClusterer(\n",
    "    clusterer_getter=lambda n_clusters: FAISSClusterer(k=n_clusters, spherical=True),\n",
    "    cluster_rule=lambda data: _accuracy(data) < 0.2,\n",
    "    stopping_rule=lambda data: _size(data) < 50,\n",
    "    max_depth=7,\n",
    "    branching_factor=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do the rule clustering ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_clusters = rule_clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define ways to display clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infembed.visualization._core.common import (\n",
    "    DisplayMetadata,\n",
    "    DisplayPIL,\n",
    "    DisplayPredictionAndLabels,\n",
    "    DisplaySingleExamples,\n",
    "    PerClusterDisplayer,\n",
    "    DisplayAccuracy,\n",
    ")\n",
    "\n",
    "rule_displayers = [\n",
    "    PerClusterDisplayer(\n",
    "        [\n",
    "            DisplayAccuracy(prediction_col=\"prediction_label\", label_col=\"label\"),\n",
    "            DisplayPredictionAndLabels(\n",
    "                prediction_col=\"prediction_label_name\", label_col=\"label_name\"\n",
    "            ),\n",
    "            # DisplaySingleExamples(\n",
    "            #     [\n",
    "            #         DisplayMetadata([\"label_name\", \"prediction_label_name\"]),\n",
    "            #         DisplayPIL(),\n",
    "            #     ],\n",
    "            #     limit=3,\n",
    "            # ),\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display the rule clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster #0\n",
      "accuracy: 0.18 (60/328)\n"
     ]
    }
   ],
   "source": [
    "for displayer in rule_displayers:\n",
    "    displayer(rule_clusters, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
