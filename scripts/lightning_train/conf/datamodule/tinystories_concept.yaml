_target_: data._utils.common.GenericDataModule
train_dataloader:
  _target_: torch.utils.data.DataLoader
  dataset:
    _target_: data._utils.common.ZipIterableDataset
    datasets:
      - _target_: data._utils.cb_llm.FnsTokenConceptDataset
        dataset: 
          _target_: data._core.tinystories.TinyStoriesDataset
          data_path: '/home/ubuntu/Documents/infembed/files/tinystories/TinyStoriesV2-GPT4-train.txt'
        fns:
        - _target_: data._core.tinystories.text_len_fn
          _args_:
            - 50
          _partial_: true
        - _target_: data._core.tinystories.has_str_fn
          _args_:
            - 'once'
          _partial_: true
        tokenizer: 
          _target_: data._core.tinystories.tinystories_tokenizer
      - _target_: data._utils.cb_llm.FnsConceptDataset
        dataset: ${..[0][dataset]}
        fns: ${..[0][fns]}
      - ${.[0][dataset]}
  # batch_size: 48
  batch_size: 40
  collate_fn:
    _target_: data._utils.common.ZipCollateFn
    collate_fns:
    - _target_: data._utils.common.RenameCollateFn
      collate_fn:
        _target_: data._utils.binary_multitask_llm.TokenMultitaskDatasetCollateFn
        max_len: 512
      rename_map:
        _target_: builtins.dict
        labels: concept_labels
    - _target_: data._utils.binary_multitask_llm.MultiTaskDatasetCollateFn
    - _target_: data._utils.llm.DecoderLLMCollateFn
      tokenizer:
        _target_: data._core.tinystories.tinystories_tokenizer
      max_len: 512 
    combiner:
      _target_: data._utils.common.dict_batch_combiner
      _partial_: true
  # num_workers: 20
  num_workers: 0
val_dataloader:
  _target_: torch.utils.data.DataLoader
  dataset:
    _target_: data._utils.common.ZipIterableDataset
    datasets:
      - _target_: data._utils.cb_llm.FnsTokenConceptDataset
        dataset: 
          _target_: data._utils.common.LimitIterableDataset
          dataset:
            _target_: data._core.tinystories.TinyStoriesDataset
            data_path: '/home/ubuntu/Documents/infembed/files/tinystories/TinyStoriesV2-GPT4-valid.txt'
          num: 3
        fns:
        - _target_: data._core.tinystories.text_len_fn
          _args_:
            - 50
          _partial_: true
        - _target_: data._core.tinystories.has_str_fn
          _args_:
            - 'once'
          _partial_: true
        tokenizer: 
          _target_: data._core.tinystories.tinystories_tokenizer
      - _target_: data._utils.cb_llm.FnsConceptDataset
        dataset: ${..[0][dataset]}
        fns: ${..[0][fns]}
      - ${.[0][dataset]}
  # batch_size: 48
  batch_size: 40
  collate_fn:
    _target_: data._utils.common.ZipCollateFn
    collate_fns:
    - _target_: data._utils.common.RenameCollateFn
      collate_fn:
        _target_: data._utils.binary_multitask_llm.TokenMultitaskDatasetCollateFn
        max_len: 512
      rename_map:
        _target_: builtins.dict
        labels: concept_labels
    - _target_: data._utils.binary_multitask_llm.MultiTaskDatasetCollateFn
    - _target_: data._utils.llm.DecoderLLMCollateFn
      tokenizer:
        _target_: data._core.tinystories.tinystories_tokenizer
      max_len: 512 
    combiner:
      _target_: data._utils.common.dict_batch_combiner
      _partial_: true
  # num_workers: 20
  num_workers: 0