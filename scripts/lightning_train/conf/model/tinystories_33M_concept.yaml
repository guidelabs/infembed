_target_: models._utils.common.load_model
model:
  _target_: models._core.binary_multitask_decoder_llm.BinaryMultitaskDecoderLightningModule
  decoder:
    _target_: models._core.binary_multitask_decoder_llm.constructor
    model_dim: 768
    key_dim: 48
    value_dim: 48
    num_heads: 16
    num_layers: 4
    dropout: 0.0
    hidden_dim: 3072
    num_tokens: 10000
    max_len: 2048
    num_concepts: 2
    concept_generator_hidden_dims:
      - 10
  loss_fn:
    _target_: models._utils.binary_multitask_llm.LLMMILImputeLoss
    # _target_: models._utils.binary_multitask_llm.LLMMilMaxLoss
    llm_loss:
      _target_: models._utils.binary_multitask_llm.LLMBinaryMultitaskLoss
      equal_batch_contribution: true
      # equal_batch_contribution: false
  configure_optimizers:
    _target_: models._utils.common.GenericConfigureOptimizers
    parameters_getter:
      _partial_: true
      _target_: models._utils.common.get_all_parameters
    optimizer_constructor:
      _partial_: true
      _target_: torch.optim.AdamW
      lr: 0.0005
      weight_decay: 0.1
      betas:
      - 0.9
      - 0.95
eval: false
checkpoints_load_func: 
  _target_: models._utils.common.default_checkpoints_load_func
  key: state_dict
  # _target_: models._utils.common.lightning_checkpoints_load_func
  _partial_: true
checkpoint: null
# checkpoint: '/home/ubuntu/Documents/infembed/scripts/misc/lightning_logs/0hiuc53z/checkpoints/epoch=0-step=4500.ckpt'