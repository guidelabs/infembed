{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "#logging.getLogger().setLevel(logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, '/home/ubuntu/Documents/infembed/infembed')\n",
    "sys.path.insert(0, '/home/ubuntu/Documents/infembed/infembed')\n",
    "sys.path.insert(0, '/home/ubuntu/Documents/infembed/data')\n",
    "from data._core.spotcheck import get_spotcheck_dataloader, get_blindspots_df\n",
    "sys.path.insert(0, '/home/ubuntu/Documents/infembed/models')\n",
    "#sys.path.insert(0, '/home/ubuntu/Documents/infembed/')\n",
    "# sys.path.insert(0, )\n",
    "from infembed.embedder._core.fast_kfac_embedder import FastKFACEmbedder\n",
    "import torchvision\n",
    "from torch.utils.data import Subset, DataLoader, default_collate, Dataset\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "import torch.nn as nn\n",
    "from infembed.clusterer._core.sklearn_clusterer import SklearnClusterer\n",
    "from infembed.clusterer._core.rule_clusterer import RuleClusterer\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List\n",
    "from infembed.utils.common import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "from models._utils.common import init_linear\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "import lightning.pytorch as pl\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate data\n",
    "For each class, generate clusters with a specified training and test label.  procedurally, define, for each cluster, training label, test label, feature generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# struct to define clusters\n",
    "@dataclass\n",
    "class Config:\n",
    "    label_generator: Callable\n",
    "    feature_generator: Callable\n",
    "    num: int\n",
    "    blindspot: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define possible `feature_generator`\n",
    "@dataclass\n",
    "class GaussianFeatureGenerator:\n",
    "    mean: Tensor\n",
    "    std: float = 1.\n",
    "\n",
    "    def __call__(self):\n",
    "        return torch.normal(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define possible `label_generator`\n",
    "@dataclass\n",
    "class CategoricalLabelGenerator:\n",
    "    probs: List[float]\n",
    "\n",
    "    def __call__(self):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        return torch.tensor(np.random.choice(len(self.probs), p=self.probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the configs\n",
    "if False:\n",
    "    std = 0.5\n",
    "    num_train = 1000\n",
    "    num_val = 100\n",
    "    num_test = 1000\n",
    "    D = 2\n",
    "    C = 2\n",
    "\n",
    "    train_configs = [\n",
    "        #Config(CategoricalLabelGenerator([0,1]), GaussianFeatureGenerator(Tensor([0, 0]), std), num_train),\n",
    "        #Config(CategoricalLabelGenerator([0,1]), GaussianFeatureGenerator(Tensor([2, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,1]), GaussianFeatureGenerator(Tensor([0, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([1,0]), GaussianFeatureGenerator(Tensor([2, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([1,0]), GaussianFeatureGenerator(Tensor([1, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([1,0]), GaussianFeatureGenerator(Tensor([3, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([1,0]), GaussianFeatureGenerator(Tensor([1, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,1]), GaussianFeatureGenerator(Tensor([3, 1]), std), num_train),\n",
    "    ]\n",
    "\n",
    "    val_configs = train_configs\n",
    "\n",
    "    test_configs = [\n",
    "        #Config(CategoricalLabelGenerator([0,1]), GaussianFeatureGenerator(Tensor([0, 0]), std), num_train),\n",
    "        #Config(CategoricalLabelGenerator([0,1]), GaussianFeatureGenerator(Tensor([2, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,1]), GaussianFeatureGenerator(Tensor([0, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0.3,0.7]), GaussianFeatureGenerator(Tensor([2, 1]), std), num_train, 1),\n",
    "        Config(CategoricalLabelGenerator([1,0]), GaussianFeatureGenerator(Tensor([1, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([1,0]), GaussianFeatureGenerator(Tensor([3, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([1,0]), GaussianFeatureGenerator(Tensor([1, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0.7,0.3]), GaussianFeatureGenerator(Tensor([3, 1]), std), num_train, 1),\n",
    "    ]\n",
    "\n",
    "if True:\n",
    "    std = 0.5\n",
    "    num_train = 1000\n",
    "    num_val = 100\n",
    "    num_test = 1000\n",
    "    D = 2\n",
    "    C = 3\n",
    "\n",
    "    # for each of 3 classes, 3 clusters, 2 of them are mis-labeled to other class\n",
    "\n",
    "    train_configs = [\n",
    "        Config(CategoricalLabelGenerator([1,0,0]), GaussianFeatureGenerator(Tensor([0, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([1,0,0]), GaussianFeatureGenerator(Tensor([2, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0.5,0.25,0.25]), GaussianFeatureGenerator(Tensor([0, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,1,0]), GaussianFeatureGenerator(Tensor([2, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0.25,0.5,0.25]), GaussianFeatureGenerator(Tensor([1, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,1,0]), GaussianFeatureGenerator(Tensor([3, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,0,1]), GaussianFeatureGenerator(Tensor([1, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0.25,0.25,0.5]), GaussianFeatureGenerator(Tensor([3, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,0,1]), GaussianFeatureGenerator(Tensor([4, 1]), std), num_train),\n",
    "    ]\n",
    "\n",
    "    val_configs = train_configs\n",
    "\n",
    "    test_configs = [\n",
    "        Config(CategoricalLabelGenerator([1,0,0]), GaussianFeatureGenerator(Tensor([0, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([1,0,0]), GaussianFeatureGenerator(Tensor([2, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([1,0,0]), GaussianFeatureGenerator(Tensor([0, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,1,0]), GaussianFeatureGenerator(Tensor([2, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,1,0]), GaussianFeatureGenerator(Tensor([1, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,1,0]), GaussianFeatureGenerator(Tensor([3, 0]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,0,1]), GaussianFeatureGenerator(Tensor([1, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,0,1]), GaussianFeatureGenerator(Tensor([3, 1]), std), num_train),\n",
    "        Config(CategoricalLabelGenerator([0,0,1]), GaussianFeatureGenerator(Tensor([4, 1]), std), num_train),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate datasets and metadata using configs\n",
    "def generate_data(configs: List[Config]):\n",
    "    xs, ys = [], []\n",
    "    metadatas = []\n",
    "    for config in configs:\n",
    "\n",
    "        def generate_data_cluster(config: Config):\n",
    "            num = config.num\n",
    "            return (\n",
    "                torch.stack([config.feature_generator() for _ in range(num)]),\n",
    "                torch.Tensor([config.label_generator() for _ in range(num)]).long(),\n",
    "            ), pd.DataFrame({\"blindspot_dummy\": (torch.ones(num) * config.blindspot).long()})\n",
    "\n",
    "        (x, y), metadata = generate_data_cluster(config)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        metadatas.append(metadata)\n",
    "\n",
    "    metadata = pd.concat(metadatas, axis=0)\n",
    "    metadata.index = list(range(len(metadata)))\n",
    "\n",
    "    return (torch.cat(xs, dim=0), torch.cat(ys, dim=0)), metadata\n",
    "\n",
    "\n",
    "class DatasetFromTuple(Dataset):\n",
    "    def __init__(self, *tup: Tuple[Tensor]):\n",
    "        self.tup = tup\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        return tuple([t[i] for t in self.tup])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(next(iter(self.tup)))\n",
    "\n",
    "\n",
    "(train_xs, train_ys), train_metadata = generate_data(train_configs)\n",
    "(val_xs, val_ys), val_metadata = generate_data(val_configs)\n",
    "(test_xs, test_ys), test_metadata = generate_data(test_configs)\n",
    "\n",
    "train_dataset = DatasetFromTuple(train_xs, train_ys)\n",
    "val_dataset = DatasetFromTuple(val_xs, val_ys)\n",
    "test_dataset = DatasetFromTuple(test_xs, test_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parameters: 20803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=2, out_features=100, bias=True)\n",
       "    (1-2): 2 x Linear(in_features=100, out_features=100, bias=True)\n",
       "    (3): Linear(in_features=100, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "    def __init__(self, dims: List[int], lr: float):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(dim_in, dim_out)\n",
    "                for (dim_in, dim_out) in zip(dims[:-1], dims[1:])\n",
    "            ]\n",
    "        )\n",
    "        self.lr = lr\n",
    "        self.apply(init_linear)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.linears[:-1]:\n",
    "            x = l(x)\n",
    "            x = torch.sigmoid(x)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "    def _step(self, batch, batch_idx):\n",
    "        # run forward\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(y_hat, y, reduction=\"mean\")\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        d = self._step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {f\"train_{key}\": val for (key, val) in d.items() if key[0] != \"_\"}\n",
    "        )\n",
    "        return d\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        d = self._step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {f\"validation_{key}\": val for (key, val) in d.items() if key[0] != \"_\"}\n",
    "        )\n",
    "        return d\n",
    "\n",
    "    def prediction_step(self, batch, batch_idx):\n",
    "        d = self._step(batch, batch_idx)\n",
    "        self.log_dict(\n",
    "            {f\"prediction_{key}\": val for (key, val) in d.items() if key[0] != \"_\"}\n",
    "        )\n",
    "        return d\n",
    "    \n",
    "\n",
    "model = MLP([D, 100, 100, 100, C], 1e-3)\n",
    "print(f\"total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "/home/ubuntu/miniconda3/envs/test2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            patience=3,\n",
    "            monitor='validation_loss',\n",
    "            mode='min',\n",
    "            verbose=True,\n",
    "            min_delta=0.1,\n",
    "            ),\n",
    "    ],\n",
    "    max_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "INFO: \n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | linears | ModuleList | 20.8 K\n",
      "---------------------------------------\n",
      "20.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.8 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | linears | ModuleList | 20.8 K\n",
      "---------------------------------------\n",
      "20.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.8 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84669f3f4b5b47c782dc20c710a1eb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/test2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/ubuntu/miniconda3/envs/test2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/ubuntu/miniconda3/envs/test2/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77a05be593649a181eacfa34eaf2467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48e72897d0c4936a09e24854f4a7b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Metric validation_loss improved. New best score: 0.932\n",
      "INFO:lightning.pytorch.callbacks.early_stopping:Metric validation_loss improved. New best score: 0.932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ec04e1d3054135821d474da23d1339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372cac77c641466389b26f6de928c250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a244d937334a4cbfb8052ab10eea1f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Monitored metric validation_loss did not improve in the last 3 records. Best score: 0.932. Signaling Trainer to stop.\n",
      "INFO:lightning.pytorch.callbacks.early_stopping:Monitored metric validation_loss did not improve in the last 3 records. Best score: 0.932. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add predictions and labels to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████████████████████████████▎                                                                                                                  | 86/282 [00:00<00:00, 858.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:00<00:00, 855.44it/s]\n"
     ]
    }
   ],
   "source": [
    "def _get_predictions_and_labels(_model, dataloader):\n",
    "    dfs = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        prediction_prob = (\n",
    "            torch.nn.functional.softmax(_model(*batch[:-1]), dim=1)\n",
    "            .detach()\n",
    "            .to(device=\"cpu\")\n",
    "        )\n",
    "        prediction_label = torch.argmax(prediction_prob, dim=1).to(device=\"cpu\")\n",
    "        label = batch[-1].to(\n",
    "            device=\"cpu\"\n",
    "        )  # assuming batch is a tensor.  if not, can check\n",
    "        # import pdb\n",
    "        # pdb.set_trace()\n",
    "        dfs.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"prediction_label\": prediction_label,\n",
    "                    \"label\": label,\n",
    "                    \"prediction_prob\": list(prediction_prob.numpy()),\n",
    "                    \"blindspot\": (prediction_label != label).float(),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    df.index = list(range(len(df)))\n",
    "    return df\n",
    "\n",
    "test_predictions = _get_predictions_and_labels(model, test_dataloader)\n",
    "test_metadata = pd.concat([test_metadata, test_predictions], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infembed.embedder._core.arnoldi_embedder import ArnoldiEmbedder\n",
    "from infembed.embedder._core.dim_reduct_embedder import PCAEmbedder\n",
    "from infembed.embedder._core.gradient_embedder import GradientEmbedder\n",
    "\n",
    "if True:\n",
    "    layers = ['linears.0','linears.1']\n",
    "if False:\n",
    "    layers = None\n",
    "\n",
    "if True:\n",
    "    projection_dim = 2\n",
    "\n",
    "if False:\n",
    "    embedder = FastKFACEmbedder(\n",
    "        layers=layers,\n",
    "        loss_fn=nn.CrossEntropyLoss(reduction='mean'),\n",
    "        sample_wise_grads_per_batch=True,\n",
    "        projection_dim=projection_dim,\n",
    "        show_progress=True,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "if False:\n",
    "    embedder = ArnoldiEmbedder(\n",
    "        layers=layers,\n",
    "        loss_fn=nn.CrossEntropyLoss(reduction='mean'),\n",
    "        sample_wise_grads_per_batch=True,\n",
    "        projection_dim=projection_dim,\n",
    "        show_progress=True,\n",
    "        model=model,\n",
    "        arnoldi_dim=20,\n",
    "        vhp='hvp',\n",
    "    )\n",
    "if True:\n",
    "    embedder = ArnoldiEmbedder(\n",
    "        layers=layers,\n",
    "        loss_fn=nn.CrossEntropyLoss(reduction='mean'),\n",
    "        sample_wise_grads_per_batch=True,\n",
    "        projection_dim=projection_dim,\n",
    "        show_progress=True,\n",
    "        model=model,\n",
    "        arnoldi_dim=20,\n",
    "        vhp='vhp',\n",
    "    )\n",
    "if False:\n",
    "    embedder = ArnoldiEmbedder(\n",
    "        layers=layers,\n",
    "        loss_fn=nn.CrossEntropyLoss(reduction='mean'),\n",
    "        sample_wise_grads_per_batch=True,\n",
    "        projection_dim=projection_dim,\n",
    "        show_progress=True,\n",
    "        model=model,\n",
    "        arnoldi_dim=20,\n",
    "        vhp='manual_hvp',\n",
    "    )\n",
    "if False:\n",
    "    embedder = ArnoldiEmbedder(\n",
    "        layers=layers,\n",
    "        loss_fn=nn.CrossEntropyLoss(reduction='mean'),\n",
    "        sample_wise_grads_per_batch=True,\n",
    "        projection_dim=projection_dim,\n",
    "        show_progress=True,\n",
    "        model=model,\n",
    "        arnoldi_dim=20,\n",
    "        vhp='manual_revrev',\n",
    "    )\n",
    "if False:\n",
    "    embedder = PCAEmbedder(\n",
    "        base_embedder=GradientEmbedder(\n",
    "            layers=layers,\n",
    "            loss_fn=nn.CrossEntropyLoss(reduction='mean'),\n",
    "            sample_wise_grads_per_batch=True,\n",
    "            show_progress=True,\n",
    "            model=model,\n",
    "        ),\n",
    "        incremental_pca_kwargs={'n_components': projection_dim},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:start arnoldi iteration\n",
      "INFO:root:start `_parameter_arnoldi`\n",
      "Running Arnoldi Iteration for step:   0%|                                                                                                                                            | 0/20 [00:00<?, ?it/s]INFO:root:arnoldi iteration step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Arnoldi Iteration for step:   5%|██████▌                                                                                                                             | 1/20 [00:00<00:17,  1.11it/s]INFO:root:arnoldi iteration step 2\n",
      "Running Arnoldi Iteration for step:  10%|█████████████▏                                                                                                                      | 2/20 [00:01<00:15,  1.15it/s]INFO:root:arnoldi iteration step 3\n",
      "Running Arnoldi Iteration for step:  15%|███████████████████▊                                                                                                                | 3/20 [00:02<00:14,  1.16it/s]INFO:root:arnoldi iteration step 4\n",
      "Running Arnoldi Iteration for step:  20%|██████████████████████████▍                                                                                                         | 4/20 [00:03<00:13,  1.17it/s]INFO:root:arnoldi iteration step 5\n",
      "Running Arnoldi Iteration for step:  25%|█████████████████████████████████                                                                                                   | 5/20 [00:04<00:12,  1.17it/s]INFO:root:arnoldi iteration step 6\n",
      "Running Arnoldi Iteration for step:  30%|███████████████████████████████████████▌                                                                                            | 6/20 [00:05<00:11,  1.18it/s]INFO:root:arnoldi iteration step 7\n",
      "Running Arnoldi Iteration for step:  35%|██████████████████████████████████████████████▏                                                                                     | 7/20 [00:05<00:11,  1.18it/s]INFO:root:arnoldi iteration step 8\n",
      "Running Arnoldi Iteration for step:  40%|████████████████████████████████████████████████████▊                                                                               | 8/20 [00:06<00:10,  1.16it/s]INFO:root:arnoldi iteration step 9\n",
      "Running Arnoldi Iteration for step:  45%|███████████████████████████████████████████████████████████▍                                                                        | 9/20 [00:07<00:09,  1.17it/s]INFO:root:arnoldi iteration step 10\n",
      "Running Arnoldi Iteration for step:  50%|█████████████████████████████████████████████████████████████████▌                                                                 | 10/20 [00:08<00:08,  1.17it/s]INFO:root:arnoldi iteration step 11\n",
      "Running Arnoldi Iteration for step:  55%|████████████████████████████████████████████████████████████████████████                                                           | 11/20 [00:09<00:07,  1.17it/s]INFO:root:arnoldi iteration step 12\n",
      "Running Arnoldi Iteration for step:  60%|██████████████████████████████████████████████████████████████████████████████▌                                                    | 12/20 [00:10<00:06,  1.18it/s]INFO:root:arnoldi iteration step 13\n",
      "Running Arnoldi Iteration for step:  65%|█████████████████████████████████████████████████████████████████████████████████████▏                                             | 13/20 [00:11<00:05,  1.18it/s]INFO:root:arnoldi iteration step 14\n",
      "Running Arnoldi Iteration for step:  70%|███████████████████████████████████████████████████████████████████████████████████████████▋                                       | 14/20 [00:11<00:05,  1.18it/s]INFO:root:arnoldi iteration step 15\n",
      "Running Arnoldi Iteration for step:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 15/20 [00:12<00:04,  1.18it/s]INFO:root:arnoldi iteration step 16\n",
      "Running Arnoldi Iteration for step:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 16/20 [00:13<00:03,  1.18it/s]INFO:root:arnoldi iteration step 17\n",
      "Running Arnoldi Iteration for step:  85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 17/20 [00:14<00:02,  1.18it/s]INFO:root:arnoldi iteration step 18\n",
      "Running Arnoldi Iteration for step:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉             | 18/20 [00:15<00:01,  1.18it/s]INFO:root:arnoldi iteration step 19\n",
      "Running Arnoldi Iteration for step:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 19/20 [00:16<00:00,  1.18it/s]INFO:root:arnoldi iteration step 20\n",
      "Running Arnoldi Iteration for step: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:17<00:00,  1.17it/s]\n",
      "INFO:root:start `_parameter_distill`\n",
      "INFO:root:start arnoldi iteration\n",
      "INFO:root:start `_parameter_arnoldi`\n",
      "Running Arnoldi Iteration for step:   0%|                                                                                                                                            | 0/20 [00:00<?, ?it/s]INFO:root:arnoldi iteration step 1\n",
      "Running Arnoldi Iteration for step:   5%|██████▌                                                                                                                             | 1/20 [00:00<00:16,  1.14it/s]INFO:root:arnoldi iteration step 2\n",
      "Running Arnoldi Iteration for step:  10%|█████████████▏                                                                                                                      | 2/20 [00:01<00:16,  1.09it/s]INFO:root:arnoldi iteration step 3\n",
      "Running Arnoldi Iteration for step:  15%|███████████████████▊                                                                                                                | 3/20 [00:02<00:15,  1.07it/s]INFO:root:arnoldi iteration step 4\n",
      "Running Arnoldi Iteration for step:  20%|██████████████████████████▍                                                                                                         | 4/20 [00:03<00:14,  1.07it/s]INFO:root:arnoldi iteration step 5\n",
      "Running Arnoldi Iteration for step:  25%|█████████████████████████████████                                                                                                   | 5/20 [00:04<00:14,  1.06it/s]INFO:root:arnoldi iteration step 6\n",
      "Running Arnoldi Iteration for step:  30%|███████████████████████████████████████▌                                                                                            | 6/20 [00:05<00:13,  1.06it/s]INFO:root:arnoldi iteration step 7\n",
      "Running Arnoldi Iteration for step:  35%|██████████████████████████████████████████████▏                                                                                     | 7/20 [00:06<00:12,  1.06it/s]INFO:root:arnoldi iteration step 8\n",
      "Running Arnoldi Iteration for step:  40%|████████████████████████████████████████████████████▊                                                                               | 8/20 [00:07<00:11,  1.06it/s]INFO:root:arnoldi iteration step 9\n",
      "Running Arnoldi Iteration for step:  45%|███████████████████████████████████████████████████████████▍                                                                        | 9/20 [00:08<00:10,  1.06it/s]INFO:root:arnoldi iteration step 10\n",
      "Running Arnoldi Iteration for step:  50%|█████████████████████████████████████████████████████████████████▌                                                                 | 10/20 [00:09<00:09,  1.06it/s]INFO:root:arnoldi iteration step 11\n",
      "Running Arnoldi Iteration for step:  55%|████████████████████████████████████████████████████████████████████████                                                           | 11/20 [00:10<00:08,  1.06it/s]INFO:root:arnoldi iteration step 12\n",
      "Running Arnoldi Iteration for step:  60%|██████████████████████████████████████████████████████████████████████████████▌                                                    | 12/20 [00:11<00:07,  1.06it/s]INFO:root:arnoldi iteration step 13\n",
      "Running Arnoldi Iteration for step:  65%|█████████████████████████████████████████████████████████████████████████████████████▏                                             | 13/20 [00:12<00:06,  1.06it/s]INFO:root:arnoldi iteration step 14\n",
      "Running Arnoldi Iteration for step:  70%|███████████████████████████████████████████████████████████████████████████████████████████▋                                       | 14/20 [00:13<00:05,  1.06it/s]INFO:root:arnoldi iteration step 15\n",
      "Running Arnoldi Iteration for step:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 15/20 [00:14<00:04,  1.06it/s]INFO:root:arnoldi iteration step 16\n",
      "Running Arnoldi Iteration for step:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 16/20 [00:15<00:03,  1.06it/s]INFO:root:arnoldi iteration step 17\n",
      "Running Arnoldi Iteration for step:  85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 17/20 [00:15<00:02,  1.06it/s]INFO:root:arnoldi iteration step 18\n",
      "Running Arnoldi Iteration for step:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉             | 18/20 [00:16<00:01,  1.06it/s]INFO:root:arnoldi iteration step 19\n",
      "Running Arnoldi Iteration for step:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 19/20 [00:17<00:00,  1.06it/s]INFO:root:arnoldi iteration step 20\n",
      "Running Arnoldi Iteration for step: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:18<00:00,  1.06it/s]\n",
      "INFO:root:start `_parameter_distill`\n",
      "INFO:root:start arnoldi iteration\n",
      "INFO:root:start `_parameter_arnoldi`\n",
      "Running Arnoldi Iteration for step:   0%|                                                                                                                                            | 0/20 [00:00<?, ?it/s]INFO:root:arnoldi iteration step 1\n",
      "Running Arnoldi Iteration for step:   5%|██████▌                                                                                                                             | 1/20 [00:00<00:16,  1.12it/s]INFO:root:arnoldi iteration step 2\n",
      "Running Arnoldi Iteration for step:  10%|█████████████▏                                                                                                                      | 2/20 [00:01<00:15,  1.13it/s]INFO:root:arnoldi iteration step 3\n",
      "Running Arnoldi Iteration for step:  15%|███████████████████▊                                                                                                                | 3/20 [00:02<00:14,  1.14it/s]INFO:root:arnoldi iteration step 4\n",
      "Running Arnoldi Iteration for step:  20%|██████████████████████████▍                                                                                                         | 4/20 [00:03<00:13,  1.15it/s]INFO:root:arnoldi iteration step 5\n",
      "Running Arnoldi Iteration for step:  25%|█████████████████████████████████                                                                                                   | 5/20 [00:04<00:12,  1.16it/s]INFO:root:arnoldi iteration step 6\n",
      "Running Arnoldi Iteration for step:  30%|███████████████████████████████████████▌                                                                                            | 6/20 [00:05<00:12,  1.17it/s]INFO:root:arnoldi iteration step 7\n",
      "Running Arnoldi Iteration for step:  35%|██████████████████████████████████████████████▏                                                                                     | 7/20 [00:06<00:11,  1.17it/s]INFO:root:arnoldi iteration step 8\n",
      "Running Arnoldi Iteration for step:  40%|████████████████████████████████████████████████████▊                                                                               | 8/20 [00:06<00:10,  1.17it/s]INFO:root:arnoldi iteration step 9\n",
      "Running Arnoldi Iteration for step:  45%|███████████████████████████████████████████████████████████▍                                                                        | 9/20 [00:07<00:09,  1.17it/s]INFO:root:arnoldi iteration step 10\n",
      "Running Arnoldi Iteration for step:  50%|█████████████████████████████████████████████████████████████████▌                                                                 | 10/20 [00:08<00:08,  1.17it/s]INFO:root:arnoldi iteration step 11\n",
      "Running Arnoldi Iteration for step:  55%|████████████████████████████████████████████████████████████████████████                                                           | 11/20 [00:09<00:07,  1.17it/s]INFO:root:arnoldi iteration step 12\n",
      "Running Arnoldi Iteration for step:  60%|██████████████████████████████████████████████████████████████████████████████▌                                                    | 12/20 [00:10<00:06,  1.17it/s]INFO:root:arnoldi iteration step 13\n",
      "Running Arnoldi Iteration for step:  65%|█████████████████████████████████████████████████████████████████████████████████████▏                                             | 13/20 [00:11<00:05,  1.17it/s]INFO:root:arnoldi iteration step 14\n",
      "Running Arnoldi Iteration for step:  70%|███████████████████████████████████████████████████████████████████████████████████████████▋                                       | 14/20 [00:11<00:05,  1.17it/s]INFO:root:arnoldi iteration step 15\n",
      "Running Arnoldi Iteration for step:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 15/20 [00:12<00:04,  1.17it/s]INFO:root:arnoldi iteration step 16\n",
      "Running Arnoldi Iteration for step:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 16/20 [00:13<00:03,  1.17it/s]INFO:root:arnoldi iteration step 17\n",
      "Running Arnoldi Iteration for step:  85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 17/20 [00:14<00:02,  1.17it/s]INFO:root:arnoldi iteration step 18\n",
      "Running Arnoldi Iteration for step:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉             | 18/20 [00:15<00:01,  1.14it/s]INFO:root:arnoldi iteration step 19\n",
      "Running Arnoldi Iteration for step:  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 19/20 [00:16<00:00,  1.11it/s]INFO:root:arnoldi iteration step 20\n",
      "Running Arnoldi Iteration for step: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:17<00:00,  1.15it/s]\n",
      "INFO:root:start `_parameter_distill`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.8 s ± 431 ms per loop (mean ± std. dev. of 2 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98c4ad460b84c2f8d4a8a0728c8d0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Using ArnoldiEmbedder to compute embeddings. Processing batch:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:compute embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e92fb9071542aa867c6049d2cbe2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Using ArnoldiEmbedder to compute embeddings. Processing batch:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:compute embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d0b8271e50406ebcf2ae23c9701304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Using ArnoldiEmbedder to compute embeddings. Processing batch:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:compute embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587 ms ± 318 µs per loop (mean ± std. dev. of 2 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9000, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit -r 2 embeddings = embedder.fit(train_dataloader)\n",
    "%timeit -r 2 embedder.predict(test_dataloader)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    n_clusters = 20\n",
    "if False:\n",
    "    n_clusters = 10\n",
    "if False:\n",
    "    n_clusters = 5\n",
    "if True:\n",
    "    n_clusters = 15\n",
    "clusterer = SklearnClusterer(sklearn_clusterer=KMeans(n_clusters=n_clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create `Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(\n",
    "    embeddings=embeddings,\n",
    "    metadata=test_metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infembed.visualization._core.common import (\n",
    "    PerClusterDisplayer,\n",
    "    DisplayAccuracy,\n",
    "    SingleClusterDisplayer,\n",
    "    DisplayCounts,\n",
    "    ClusterAUCDisplayer,\n",
    ")\n",
    "\n",
    "\n",
    "displayers = [\n",
    "    ClusterAUCDisplayer('blindspot'),\n",
    "    PerClusterDisplayer(\n",
    "        [\n",
    "            DisplayAccuracy(prediction_col=\"prediction_label\", label_col=\"label\"),\n",
    "            DisplayCounts(['blindspot', 'label'])\n",
    "            ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for blindspot: 0.9537726000810658\n",
      "cluster #0\n",
      "accuracy: 0.32 (231/718)\n",
      "blindspot: {0.0: 231, 1.0: 487}\n",
      "label: {1: 718}\n",
      "cluster #1\n",
      "accuracy: 1.00 (834/834)\n",
      "blindspot: {0.0: 834}\n",
      "label: {2: 834}\n",
      "cluster #2\n",
      "accuracy: 0.84 (332/395)\n",
      "blindspot: {0.0: 332, 1.0: 63}\n",
      "label: {0: 395}\n",
      "cluster #3\n",
      "accuracy: 0.95 (757/800)\n",
      "blindspot: {0.0: 757, 1.0: 43}\n",
      "label: {1: 800}\n",
      "cluster #4\n",
      "accuracy: 0.16 (94/600)\n",
      "blindspot: {0.0: 94, 1.0: 506}\n",
      "label: {0: 600}\n",
      "cluster #5\n",
      "accuracy: 1.00 (931/931)\n",
      "blindspot: {0.0: 931}\n",
      "label: {0: 931}\n",
      "cluster #6\n",
      "accuracy: 0.05 (13/253)\n",
      "blindspot: {0.0: 13, 1.0: 240}\n",
      "label: {2: 253}\n",
      "cluster #7\n",
      "accuracy: 0.10 (82/802)\n",
      "blindspot: {0.0: 82, 1.0: 720}\n",
      "label: {1: 802}\n",
      "cluster #8\n",
      "accuracy: 0.36 (83/232)\n",
      "blindspot: {0.0: 83, 1.0: 149}\n",
      "label: {2: 232}\n",
      "cluster #9\n",
      "accuracy: 0.92 (846/921)\n",
      "blindspot: {0.0: 846, 1.0: 75}\n",
      "label: {2: 921}\n",
      "cluster #10\n",
      "accuracy: 0.01 (3/478)\n",
      "blindspot: {0.0: 3, 1.0: 475}\n",
      "label: {0: 478}\n",
      "cluster #11\n",
      "accuracy: 0.92 (624/680)\n",
      "blindspot: {0.0: 624, 1.0: 56}\n",
      "label: {1: 680}\n",
      "cluster #12\n",
      "accuracy: 0.95 (213/225)\n",
      "blindspot: {0.0: 213, 1.0: 12}\n",
      "label: {2: 225}\n",
      "cluster #13\n",
      "accuracy: 0.10 (53/535)\n",
      "blindspot: {0.0: 53, 1.0: 482}\n",
      "label: {2: 535}\n",
      "cluster #14\n",
      "accuracy: 1.00 (596/596)\n",
      "blindspot: {0.0: 596}\n",
      "label: {0: 596}\n"
     ]
    }
   ],
   "source": [
    "for displayer in displayers:\n",
    "    displayer(clusters, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do everything, but for different embedders, clusterers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
