{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from infembed.embedder._core.fast_kfac_embedder import FastKFACEmbedder\n",
    "import torchvision\n",
    "from torch.utils.data import Subset, DataLoader, default_collate, Dataset\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "import torch.nn as nn\n",
    "from infembed.clusterer._core.sklearn_clusterer import SklearnClusterer\n",
    "from infembed.clusterer._core.rule_clusterer import RuleClusterer\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List\n",
    "from infembed.utils.common import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure out device to compute embeddings on ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define data\n",
    "We will define the following:\n",
    "- `eval_dataloader`: `DataLoader` for evaluation data.  This is used to compute embeddings for the evaluation data\n",
    "- `eval_dataset`: `Dataset` for evaluation data.  This is used to retrieve individual examples for displaying.\n",
    "- `train_dataloader`: `DataLoader` for training data.  This is needed to know how to compute embeddings for the evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = ResNet18_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "def collate_fn(examples):\n",
    "    return tuple([_x.to(device=DEVICE) for _x in default_collate([(normalize(__x[0]), __x[1]) for __x in examples])])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EVAL = 5000\n",
    "eval_dataset = Subset(\n",
    "    torchvision.datasets.ImageNet(\"../data/files/imagenet\", split=\"val\"),\n",
    "    range(NUM_EVAL),\n",
    ")\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=collate_fn, batch_size=BATCH_SIZE)\n",
    "\n",
    "_train_data = torchvision.datasets.ImageNet(\"../data/files/imagenet\", split=\"val\")\n",
    "NUM_TRAIN = 500\n",
    "train_data = Subset(_train_data, torch.randperm(len(_train_data))[:NUM_TRAIN])\n",
    "train_dataloader = DataLoader(train_data, collate_fn=collate_fn, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT).to(device=DEVICE)\n",
    "# model.load_state_dict(ResNet18_Weights.IMAGENET1K_V1.get_state_dict(progress=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define embedder ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = FastKFACEmbedder(\n",
    "    model=model,\n",
    "    layers=[\n",
    "        \"fc\",\n",
    "        # \"layer4.0.conv1\",\n",
    "        # \"layer4.0.conv2\",\n",
    "        # \"layer4.0.downsample.0\",\n",
    "        # \"layer4.1.conv1\",\n",
    "        \"layer4.1.conv2\",\n",
    "    ],\n",
    "    loss_fn=nn.CrossEntropyLoss(reduction=\"sum\"),\n",
    "    sample_wise_grads_per_batch=True,\n",
    "    projection_dim=50,\n",
    "    projection_on_cpu=True,\n",
    "    show_progress=True,\n",
    "    per_layer_blocks=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit embedder ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing `hessian_dataset` batch:   0%|                                                                                                                                                                                    | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/test2/lib/python3.9/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "processing `hessian_dataset` batch: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "embedder.fit(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute embeddings for evaluation data ###\n",
    "we then package them into a `Data` instance, which contains all kinds of data that could possibly be used to do the subsequent clustering, i.e. including tabular metadata as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7529e0820e8c4810983dda6f8d3068d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Using FastKFACEmbedder to compute influence embeddings. Processing batch:   0%|          | 0/157 [00:00<?, ?it…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = embedder.predict(eval_dataloader)\n",
    "data = Data(embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define clusterer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = SklearnClusterer(sklearn_clusterer=KMeans(n_clusters=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do the clustering ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute metadata for evaluation data ###\n",
    "this will be the ingredient needed to display the clusters.  later on, it will also be used by the rule-based clusterer.  therefore, we also add it to the running `Data` instance for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:45<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "def _get_predictions_and_labels(_model, dataloader):\n",
    "    dfs = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        prediction_prob = (\n",
    "            torch.nn.functional.softmax(_model(*batch[:-1]), dim=1)\n",
    "            .detach()\n",
    "            .to(device=\"cpu\")\n",
    "        )\n",
    "        prediction_label = torch.argmax(prediction_prob, dim=1).to(device=\"cpu\")\n",
    "        label = batch[-1].to(\n",
    "            device=\"cpu\"\n",
    "        )  # assuming batch is a tensor.  if not, can check\n",
    "        dfs.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"prediction_label\": prediction_label,\n",
    "                    \"label\": label,\n",
    "                    \"prediction_prob\": list(prediction_prob.numpy()),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    df.index = list(range(len(df)))\n",
    "    return df\n",
    "\n",
    "metadata = _get_predictions_and_labels(model, eval_dataloader)\n",
    "data.metadata = metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define ways to display clusters ###\n",
    "these will all be functions whose input is a list of list of indices in the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infembed.visualization._core.common import PerClusterDisplayer, DisplayAccuracy\n",
    "\n",
    "displayers = [\n",
    "    PerClusterDisplayer([\n",
    "        DisplayAccuracy(prediction_col='prediction_label', label_col='label')\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display the clusters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster #0\n",
      "accuracy: 0.18 (55/307)\n",
      "cluster #1\n",
      "accuracy: 0.27 (7/26)\n",
      "cluster #2\n",
      "accuracy: 0.84 (3710/4426)\n",
      "cluster #3\n",
      "accuracy: 0.16 (6/37)\n",
      "cluster #4\n",
      "accuracy: 0.33 (13/39)\n",
      "cluster #5\n",
      "accuracy: 0.20 (13/66)\n",
      "cluster #6\n",
      "accuracy: 0.27 (11/41)\n",
      "cluster #7\n",
      "accuracy: 0.00 (0/1)\n",
      "cluster #8\n",
      "accuracy: 0.10 (3/29)\n",
      "cluster #9\n",
      "accuracy: 0.32 (9/28)\n"
     ]
    }
   ],
   "source": [
    "for displayer in displayers:\n",
    "    displayer(clusters, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define rule clusterer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _accuracy(data):\n",
    "    return (data.metadata[\"prediction_label\"] == data.metadata[\"label\"]).mean()\n",
    "\n",
    "\n",
    "def _size(data):\n",
    "    return len(data)\n",
    "\n",
    "\n",
    "rule_clusterer = RuleClusterer(\n",
    "    clusterer_getter=lambda n_clusters: SklearnClusterer(KMeans(n_clusters=n_clusters)),\n",
    "    cluster_rule=lambda data: _accuracy(data) < 0.2,\n",
    "    stopping_rule=lambda data: _size(data) < 50,\n",
    "    max_depth=5,\n",
    "    branching_factor=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do the rule clustering ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_clusters = rule_clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display the rule clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster #0\n",
      "accuracy: 0.18 (60/328)\n"
     ]
    }
   ],
   "source": [
    "for displayer in displayers:\n",
    "    displayer(rule_clusters, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
