{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pdb\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, '/home/ubuntu/Documents/infembed/infembed')\n",
    "sys.path.insert(0, '/home/ubuntu/Documents/infembed/infembed')\n",
    "sys.path.insert(0, '/home/ubuntu/Documents/infembed/data')\n",
    "from data._core.spotcheck import get_spotcheck_dataloader, get_blindspots_df\n",
    "sys.path.insert(0, '/home/ubuntu/Documents/infembed/models')\n",
    "#sys.path.insert(0, '/home/ubuntu/Documents/infembed/')\n",
    "# sys.path.insert(0, )\n",
    "from infembed.embedder._core.fast_kfac_embedder import FastKFACEmbedder\n",
    "import torchvision\n",
    "from torch.utils.data import Subset, DataLoader, default_collate, Dataset\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "import torch.nn as nn\n",
    "from infembed.clusterer._core.sklearn_clusterer import SklearnClusterer\n",
    "from infembed.clusterer._core.rule_clusterer import RuleClusterer\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List\n",
    "from infembed.utils.common import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "from models._utils.common import init_linear\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "import lightning.pytorch as pl\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure out device to compute embeddings on ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define data\n",
    "We will define the following:\n",
    "- `eval_dataset`: `Dataset` for evaluation data.  This is used to retrieve individual examples for displaying.  This should be the same data for which the embeddings we load later were computed\n",
    "- `eval_dataloader`: `DataLoader` for evaluation data.  This is used to compute metadata for the evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = ResNet18_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "def collate_fn(examples):\n",
    "    return tuple([_x.to(device=DEVICE) for _x in default_collate([(normalize(__x[0]), __x[1]) for __x in examples])])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EVAL = 50000\n",
    "eval_dataset = Subset(\n",
    "    torchvision.datasets.ImageNet(\"/home/ubuntu/Documents/infembed/data/files/imagenet\", split=\"val\"),\n",
    "    range(NUM_EVAL),\n",
    ")\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=collate_fn, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model ###\n",
    "only used to get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(weights=ResNet18_Weights.DEFAULT).to(device=DEVICE)\n",
    "# model.load_state_dict(ResNet18_Weights.IMAGENET1K_V1.get_state_dict(progress=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load embeddings for evaluation data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 195])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings_path = '/home/ubuntu/Documents/infembed/infembed/scripts/run_embedder/outputs/imagenet_timing_experiments/0/embeddings.pt'\n",
    "# embeddings_path = '/home/ubuntu/Documents/infembed/infembed/scripts/run_embedder/outputs/imagenet_kfac_global_projection_dim/1/embeddings.pt'\n",
    "# embeddings_path = '/home/ubuntu/Documents/infembed/infembed/scripts/run_embedder/outputs/imagenet_kfac_last_layer/2/embeddings.pt'\n",
    "# embeddings_path = '/home/ubuntu/Documents/infembed/infembed/scripts/run_embedder/outputs/imagenet_gradient_last_layer/0/embeddings.pt'\n",
    "# embeddings_path = '/home/ubuntu/Documents/infembed/infembed/scripts/run_embedder/outputs/imagenet_dim_1000/0/embeddings.pt'\n",
    "# embeddings_path = '/home/ubuntu/Documents/infembed/infembed/examples/imagenet/hydra_outputs/run_embeddings/imagenet_pca_gradient/4/embeddings.pt' # pca gradient 1000 dim\n",
    "embeddings_path = '/home/ubuntu/Documents/infembed/infembed/examples/imagenet/hydra_outputs/run_embeddings/imagenet_arnoldi/3/embeddings.pt' # arnoldi \n",
    "embeddings = torch.load(open(embeddings_path, 'rb'))\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optionally, we can only keep some elements of the embedding (relevant for `ArnoldiEmbedder`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS_TO_KEEP = 50\n",
    "if DIMS_TO_KEEP is not None:\n",
    "    embeddings = embeddings[:, -DIMS_TO_KEEP:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optionally, we can normalize the embeddings to have the same norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE = False\n",
    "if NORMALIZE:\n",
    "    embeddings = embeddings / torch.linalg.norm(embeddings, dim=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # already assume embeddings fit in memory, so no point in using incremental methods\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we then package them into a `Data` instance, which contains all kinds of data that could possibly be used to do the subsequent clustering, i.e. including tabular metadata as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute metadata for evaluation data ###\n",
    "this will be the ingredient needed to display the clusters.  later on, it will also be used by the rule-based clusterer.  therefore, we also add it to the running `Data` instance for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_predictions_and_labels(_model, dataloader):\n",
    "    dfs = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        prediction_prob = (\n",
    "            torch.nn.functional.softmax(_model(*batch[:-1]), dim=1)\n",
    "            .detach()\n",
    "            .to(device=\"cpu\")\n",
    "        )\n",
    "        prediction_label = torch.argmax(prediction_prob, dim=1).to(device=\"cpu\")\n",
    "        label = batch[-1].to(\n",
    "            device=\"cpu\"\n",
    "        )  # assuming batch is a tensor.  if not, can check\n",
    "        dfs.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"prediction_label\": prediction_label,\n",
    "                    \"label\": label,\n",
    "                    \"prediction_prob\": list(prediction_prob.numpy()),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    df.index = list(range(len(df)))\n",
    "    return df\n",
    "\n",
    "if False:\n",
    "    metadata = _get_predictions_and_labels(model, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.metadata = metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define clusterer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = SklearnClusterer(sklearn_clusterer=KMeans(n_clusters=25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do the clustering ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define ways to display clusters ###\n",
    "these will all be functions whose input is a list of list of indices in the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infembed.visualization._core.common import (\n",
    "    DisplayMetadata,\n",
    "    DisplayPIL,\n",
    "    DisplayPredictionAndLabels,\n",
    "    DisplaySingleExamples,\n",
    "    PerClusterDisplayer,\n",
    "    DisplayAccuracy,\n",
    ")\n",
    "\n",
    "displayers = [\n",
    "    PerClusterDisplayer(\n",
    "        [\n",
    "            DisplayAccuracy(prediction_col=\"prediction_label\", label_col=\"label\"),\n",
    "            DisplayPredictionAndLabels(\n",
    "                prediction_col=\"prediction_label\", label_col=\"label\"\n",
    "            ),\n",
    "            DisplaySingleExamples([\n",
    "                DisplayMetadata(['label', 'prediction_label']),\n",
    "                DisplayPIL(),\n",
    "            ], limit=3),\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display the clusters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster #0\n",
      "accuracy: 0.70 (34046/48800)\n",
      "prediction: {819: 92, 424: 90, 679: 82, 926: 81, 238: 79, 162: 77, 159: 76, 61: 75, 391: 75, 234: 74, 518: 72, 523: 72, 474: 71, 788: 71, 766: 70, 681: 70, 407: 69, 379: 69, 894: 69, 249: 69, 505: 68, 352: 68, 281: 68, 570: 68, 895: 67, 652: 67, 489: 67, 349: 67, 431: 67, 965: 66, 189: 66, 929: 66, 903: 66, 781: 65, 654: 65, 799: 65, 617: 65, 713: 65, 497: 64, 382: 64, 544: 64, 225: 64, 48: 64, 849: 64, 526: 64, 35: 64, 286: 64, 562: 63, 528: 63, 608: 63, 180: 63, 463: 63, 581: 63, 659: 63, 553: 63, 671: 63, 410: 63, 496: 63, 611: 62, 941: 62, 411: 62, 23: 62, 425: 62, 716: 62, 217: 62, 74: 62, 263: 62, 579: 62, 916: 62, 801: 62, 455: 62, 684: 61, 614: 61, 58: 61, 191: 61, 777: 61, 909: 61, 198: 61, 248: 61, 421: 61, 472: 61, 593: 61, 695: 61, 973: 61, 209: 60, 223: 60, 275: 60, 982: 60, 605: 60, 487: 60, 445: 60, 774: 60, 269: 60, 850: 60, 917: 60, 182: 60, 72: 60, 933: 60, 50: 60, 512: 60, 990: 60, 441: 60, 448: 60, 255: 60, 927: 60, 732: 59, 979: 59, 164: 59, 722: 59, 515: 59, 458: 59, 404: 59, 591: 59, 892: 59, 669: 59, 433: 59, 560: 59, 768: 59, 295: 59, 274: 59, 344: 59, 500: 59, 698: 59, 428: 59, 642: 59, 937: 59, 636: 59, 971: 59, 77: 59, 704: 59, 55: 59, 172: 59, 420: 59, 495: 59, 582: 59, 563: 58, 992: 58, 945: 58, 612: 58, 284: 58, 759: 58, 436: 58, 783: 58, 873: 58, 884: 58, 333: 58, 471: 58, 709: 58, 667: 58, 197: 58, 981: 58, 327: 58, 313: 58, 677: 58, 292: 58, 343: 58, 372: 58, 232: 58, 6: 58, 721: 57, 525: 57, 301: 57, 242: 57, 880: 57, 203: 57, 208: 57, 922: 57, 771: 57, 587: 57, 866: 57, 101: 57, 886: 57, 726: 57, 57: 57, 785: 57, 359: 57, 293: 57, 896: 57, 743: 57, 415: 57, 760: 57, 453: 57, 805: 57, 457: 57, 40: 57, 603: 57, 174: 57, 155: 57, 53: 57, 336: 57, 625: 57, 115: 57, 154: 56, 131: 56, 267: 56, 150: 56, 384: 56, 306: 56, 85: 56, 71: 56, 773: 56, 485: 56, 76: 56, 357: 56, 171: 56, 412: 56, 918: 56, 452: 56, 739: 56, 843: 56, 734: 56, 763: 56, 235: 56, 870: 56, 13: 56, 177: 56, 787: 56, 144: 56, 738: 56, 668: 56, 703: 56, 522: 56, 449: 55, 951: 55, 41: 55, 483: 55, 527: 55, 399: 55, 692: 55, 486: 55, 243: 55, 508: 55, 688: 55, 532: 55, 31: 55, 406: 55, 913: 55, 548: 55, 702: 55, 300: 55, 661: 55, 524: 55, 784: 55, 573: 55, 565: 55, 761: 55, 506: 55, 943: 55, 218: 55, 139: 55, 202: 55, 989: 55, 200: 55, 792: 55, 26: 55, 834: 55, 317: 54, 259: 54, 257: 54, 195: 54, 161: 54, 364: 54, 361: 54, 865: 54, 974: 54, 770: 54, 207: 54, 536: 54, 288: 54, 378: 54, 316: 54, 848: 54, 477: 54, 863: 54, 104: 54, 291: 54, 396: 54, 146: 54, 847: 54, 607: 54, 253: 54, 711: 54, 888: 54, 310: 54, 694: 54, 944: 54, 106: 54, 484: 54, 685: 54, 683: 54, 898: 54, 956: 54, 535: 53, 315: 53, 245: 53, 279: 53, 181: 53, 874: 53, 129: 53, 124: 53, 376: 53, 664: 53, 576: 53, 919: 53, 706: 53, 132: 53, 37: 53, 920: 53, 797: 53, 921: 53, 230: 53, 637: 53, 66: 53, 569: 53, 648: 53, 294: 53, 543: 53, 258: 53, 367: 53, 151: 53, 537: 53, 346: 53, 604: 53, 670: 53, 138: 53, 871: 53, 90: 52, 120: 52, 107: 52, 4: 52, 229: 52, 645: 52, 538: 52, 993: 52, 403: 52, 22: 52, 946: 52, 816: 52, 571: 52, 561: 52, 631: 52, 178: 52, 756: 52, 239: 52, 666: 52, 30: 52, 119: 52, 876: 52, 583: 52, 454: 52, 882: 52, 247: 52, 362: 52, 237: 52, 67: 52, 332: 52, 322: 52, 456: 52, 214: 52, 831: 52, 156: 52, 580: 52, 924: 52, 723: 52, 44: 52, 360: 52, 251: 52, 192: 52, 440: 52, 984: 52, 842: 52, 995: 52, 959: 52, 957: 52, 568: 52, 92: 51, 948: 51, 655: 51, 586: 51, 751: 51, 547: 51, 69: 51, 265: 51, 266: 51, 219: 51, 639: 51, 634: 51, 492: 51, 550: 51, 747: 51, 102: 51, 137: 51, 254: 51, 491: 51, 983: 51, 147: 51, 283: 51, 988: 51, 350: 51, 387: 51, 615: 51, 757: 51, 802: 51, 111: 51, 610: 51, 19: 51, 136: 51, 94: 51, 233: 51, 256: 51, 520: 51, 278: 51, 626: 51, 113: 51, 205: 51, 822: 51, 950: 51, 468: 51, 832: 51, 9: 51, 914: 51, 775: 51, 697: 51, 934: 51, 545: 51, 370: 50, 305: 50, 397: 50, 63: 50, 938: 50, 640: 50, 594: 50, 82: 50, 912: 50, 952: 50, 621: 50, 997: 50, 215: 50, 814: 50, 75: 50, 125: 50, 320: 50, 142: 50, 839: 50, 542: 50, 701: 50, 199: 50, 342: 50, 81: 50, 890: 50, 807: 50, 658: 50, 985: 50, 393: 50, 116: 50, 991: 50, 552: 50, 321: 50, 354: 50, 280: 50, 338: 50, 307: 50, 351: 50, 793: 50, 212: 50, 900: 50, 511: 50, 936: 50, 160: 50, 719: 50, 17: 50, 18: 50, 392: 50, 29: 50, 630: 50, 337: 50, 21: 49, 133: 49, 791: 49, 143: 49, 8: 49, 809: 49, 932: 49, 718: 49, 628: 49, 554: 49, 394: 49, 3: 49, 717: 49, 599: 49, 867: 49, 377: 49, 795: 49, 714: 49, 366: 49, 398: 49, 88: 49, 390: 49, 978: 49, 574: 49, 388: 49, 439: 49, 955: 49, 490: 49, 939: 49, 311: 49, 970: 49, 244: 49, 340: 49, 656: 49, 153: 49, 213: 49, 444: 49, 476: 49, 507: 49, 475: 49, 533: 49, 682: 49, 112: 49, 70: 49, 779: 49, 109: 49, 840: 49, 529: 49, 118: 49, 442: 49, 430: 49, 166: 49, 201: 49, 28: 49, 95: 49, 725: 49, 14: 49, 10: 49, 755: 49, 646: 49, 100: 49, 980: 48, 597: 48, 385: 48, 339: 48, 750: 48, 89: 48, 15: 48, 829: 48, 653: 48, 157: 48, 186: 48, 953: 48, 252: 48, 480: 48, 130: 48, 942: 48, 169: 48, 746: 48, 767: 48, 473: 48, 749: 48, 820: 48, 417: 48, 470: 48, 859: 48, 588: 48, 204: 48, 769: 48, 451: 48, 423: 48, 598: 48, 216: 48, 270: 48, 672: 48, 314: 48, 56: 48, 745: 48, 330: 48, 135: 48, 80: 48, 427: 48, 736: 48, 148: 48, 986: 48, 105: 48, 303: 48, 803: 48, 401: 48, 328: 48, 858: 48, 319: 48, 540: 48, 24: 48, 878: 48, 33: 47, 931: 47, 915: 47, 325: 47, 373: 47, 837: 47, 365: 47, 877: 47, 308: 47, 289: 47, 358: 47, 825: 47, 462: 47, 502: 47, 879: 47, 872: 47, 674: 47, 91: 47, 46: 47, 318: 47, 754: 47, 753: 47, 651: 47, 140: 47, 967: 47, 618: 47, 629: 47, 572: 47, 875: 47, 173: 47, 261: 47, 466: 47, 145: 47, 419: 47, 823: 47, 363: 47, 450: 47, 800: 47, 99: 47, 7: 47, 312: 47, 42: 47, 1: 47, 52: 47, 730: 47, 857: 47, 426: 47, 39: 47, 762: 47, 323: 47, 510: 47, 514: 47, 2: 46, 65: 46, 96: 46, 467: 46, 566: 46, 395: 46, 687: 46, 16: 46, 141: 46, 835: 46, 409: 46, 221: 46, 210: 46, 578: 46, 347: 46, 881: 46, 324: 46, 696: 46, 504: 46, 632: 46, 276: 46, 194: 46, 460: 46, 627: 46, 680: 46, 966: 46, 616: 46, 331: 46, 592: 46, 127: 46, 902: 46, 122: 46, 854: 45, 606: 45, 98: 45, 828: 45, 602: 45, 12: 45, 737: 45, 960: 45, 972: 45, 513: 45, 649: 45, 236: 45, 996: 45, 121: 45, 935: 45, 51: 45, 595: 45, 963: 45, 369: 45, 184: 45, 326: 45, 887: 45, 923: 45, 962: 45, 222: 45, 812: 45, 84: 45, 830: 45, 309: 45, 998: 45, 413: 45, 744: 45, 930: 45, 375: 45, 25: 45, 11: 45, 34: 45, 530: 45, 817: 45, 650: 44, 176: 44, 663: 44, 272: 44, 422: 44, 846: 44, 329: 44, 206: 44, 368: 44, 179: 44, 727: 44, 928: 44, 299: 44, 905: 44, 613: 44, 539: 44, 833: 44, 83: 44, 724: 44, 416: 44, 260: 44, 103: 44, 765: 44, 559: 44, 958: 44, 609: 44, 644: 44, 821: 44, 0: 44, 43: 44, 87: 44, 45: 44, 334: 43, 432: 43, 226: 43, 287: 43, 977: 43, 790: 43, 297: 43, 868: 43, 715: 43, 446: 43, 296: 43, 298: 43, 853: 43, 149: 43, 549: 43, 735: 43, 414: 43, 907: 43, 776: 43, 758: 43, 954: 43, 575: 43, 227: 43, 228: 43, 123: 43, 808: 43, 273: 43, 93: 43, 551: 43, 893: 43, 557: 43, 494: 43, 128: 43, 564: 43, 517: 43, 782: 42, 851: 42, 27: 42, 290: 42, 335: 42, 994: 42, 778: 42, 38: 42, 241: 42, 246: 42, 437: 42, 584: 42, 168: 42, 976: 42, 904: 42, 789: 42, 20: 42, 196: 42, 855: 42, 534: 42, 577: 42, 185: 42, 277: 42, 211: 42, 693: 41, 794: 41, 665: 41, 383: 41, 869: 41, 170: 41, 262: 41, 78: 41, 268: 41, 224: 41, 660: 41, 114: 41, 97: 41, 459: 41, 47: 41, 641: 41, 345: 41, 464: 41, 780: 41, 555: 41, 619: 41, 891: 41, 546: 41, 731: 41, 443: 41, 700: 41, 402: 41, 889: 41, 862: 41, 690: 41, 285: 41, 117: 41, 405: 40, 5: 40, 910: 40, 708: 40, 806: 40, 975: 40, 264: 40, 752: 40, 435: 40, 447: 40, 824: 40, 796: 40, 110: 40, 707: 40, 521: 40, 348: 40, 408: 40, 429: 39, 79: 39, 740: 39, 190: 39, 488: 39, 60: 39, 852: 39, 742: 39, 152: 39, 818: 39, 733: 39, 856: 39, 624: 39, 710: 39, 622: 39, 187: 39, 826: 39, 772: 39, 589: 39, 36: 38, 49: 38, 389: 38, 54: 38, 519: 38, 183: 38, 601: 38, 434: 38, 380: 38, 134: 38, 699: 38, 720: 38, 386: 38, 786: 38, 478: 38, 815: 38, 86: 38, 418: 37, 374: 37, 804: 37, 531: 37, 925: 37, 949: 37, 838: 37, 657: 37, 647: 37, 304: 37, 355: 37, 827: 37, 883: 37, 798: 37, 126: 37, 643: 36, 635: 36, 901: 36, 947: 36, 861: 36, 503: 36, 64: 36, 686: 36, 864: 36, 748: 36, 810: 36, 844: 36, 940: 36, 676: 36, 371: 36, 678: 35, 662: 35, 899: 35, 860: 35, 741: 35, 341: 35, 271: 35, 845: 35, 764: 35, 558: 35, 481: 35, 987: 35, 897: 35, 673: 34, 469: 34, 231: 34, 220: 34, 968: 34, 691: 34, 811: 34, 108: 34, 908: 33, 728: 33, 620: 33, 498: 32, 596: 32, 712: 32, 961: 32, 193: 32, 240: 32, 964: 32, 165: 32, 188: 32, 499: 32, 59: 32, 461: 32, 541: 32, 556: 31, 841: 31, 567: 31, 479: 31, 999: 30, 969: 30, 638: 30, 73: 30, 729: 30, 509: 30, 501: 30, 400: 30, 590: 30, 482: 29, 813: 29, 705: 28, 302: 28, 356: 28, 158: 28, 465: 28, 175: 28, 163: 28, 911: 27, 62: 27, 353: 27, 250: 27, 381: 27, 675: 27, 438: 27, 32: 27, 68: 24, 633: 21, 585: 21, 689: 20, 600: 20, 493: 18, 282: 18, 516: 18, 836: 17, 167: 17, 623: 15, 906: 13, 885: 11}\n",
      "label: {999: 50, 0: 50, 997: 50, 957: 50, 959: 50, 960: 50, 947: 50, 941: 50, 943: 50, 932: 50, 934: 50, 936: 50, 937: 50, 60: 50, 61: 50, 62: 50, 66: 50, 48: 50, 49: 50, 42: 50, 923: 50, 927: 50, 915: 50, 916: 50, 912: 50, 902: 50, 903: 50, 904: 50, 906: 50, 892: 50, 893: 50, 894: 50, 895: 50, 898: 50, 880: 50, 882: 50, 868: 50, 873: 50, 91: 50, 98: 50, 84: 50, 80: 50, 81: 50, 74: 50, 860: 50, 863: 50, 852: 50, 853: 50, 854: 50, 857: 50, 835: 50, 837: 50, 827: 50, 828: 50, 829: 50, 830: 50, 831: 50, 832: 50, 834: 50, 819: 50, 811: 50, 815: 50, 804: 50, 805: 50, 797: 50, 798: 50, 792: 50, 794: 50, 779: 50, 781: 50, 783: 50, 784: 50, 786: 50, 771: 50, 129: 50, 130: 50, 118: 50, 119: 50, 107: 50, 106: 50, 765: 50, 766: 50, 769: 50, 759: 50, 761: 50, 748: 50, 750: 50, 751: 50, 753: 50, 740: 50, 742: 50, 733: 50, 734: 50, 724: 50, 725: 50, 728: 50, 729: 50, 716: 50, 717: 50, 710: 50, 713: 50, 157: 50, 159: 50, 139: 50, 145: 50, 146: 50, 133: 50, 701: 50, 702: 50, 693: 50, 694: 50, 684: 50, 687: 50, 676: 50, 671: 50, 662: 50, 663: 50, 665: 50, 651: 50, 653: 50, 646: 50, 647: 50, 650: 50, 637: 50, 627: 50, 620: 50, 621: 50, 624: 50, 625: 50, 612: 50, 616: 50, 610: 50, 595: 50, 596: 50, 598: 50, 587: 50, 590: 50, 580: 50, 192: 50, 179: 50, 181: 50, 183: 50, 171: 50, 172: 50, 174: 50, 176: 50, 178: 50, 166: 50, 168: 50, 170: 50, 574: 50, 576: 50, 578: 50, 563: 50, 566: 50, 558: 50, 562: 50, 554: 50, 543: 50, 533: 50, 535: 50, 537: 50, 525: 50, 511: 50, 512: 50, 514: 50, 499: 50, 501: 50, 502: 50, 503: 50, 505: 50, 506: 50, 497: 50, 484: 50, 485: 50, 486: 50, 487: 50, 221: 50, 222: 50, 226: 50, 211: 50, 213: 50, 214: 50, 217: 50, 210: 50, 196: 50, 199: 50, 475: 50, 468: 50, 473: 50, 459: 50, 463: 50, 451: 50, 453: 50, 454: 50, 456: 50, 457: 50, 243: 50, 245: 50, 247: 50, 250: 50, 235: 50, 236: 50, 242: 50, 231: 50, 444: 50, 445: 50, 442: 50, 430: 50, 433: 50, 420: 50, 423: 50, 411: 50, 413: 50, 415: 50, 404: 50, 408: 50, 396: 50, 397: 50, 399: 50, 391: 50, 393: 50, 379: 50, 381: 50, 386: 50, 372: 50, 374: 50, 376: 50, 378: 50, 365: 50, 369: 50, 356: 50, 359: 50, 361: 50, 283: 50, 289: 50, 290: 50, 275: 50, 276: 50, 277: 50, 279: 50, 281: 50, 282: 50, 270: 50, 271: 50, 274: 50, 266: 50, 348: 50, 351: 50, 345: 50, 332: 50, 333: 50, 336: 50, 338: 50, 324: 50, 327: 50, 321: 50, 322: 50, 309: 50, 312: 50, 303: 50, 304: 50, 293: 50, 295: 50, 988: 50, 990: 50, 993: 50, 994: 50, 980: 50, 982: 50, 971: 50, 973: 50, 974: 50, 977: 50, 963: 50, 967: 50, 969: 50, 27: 50, 29: 50, 30: 50, 31: 50, 34: 50, 19: 50, 21: 50, 26: 50, 14: 50, 18: 50, 3: 50, 6: 50, 9: 50, 10: 50, 1: 49, 4: 49, 5: 49, 7: 49, 8: 49, 54: 49, 56: 49, 57: 49, 43: 49, 45: 49, 46: 49, 47: 49, 926: 49, 36: 49, 37: 49, 38: 49, 918: 49, 921: 49, 922: 49, 924: 49, 925: 49, 323: 49, 331: 49, 314: 49, 316: 49, 318: 49, 320: 49, 301: 49, 306: 49, 307: 49, 310: 49, 291: 49, 292: 49, 297: 49, 300: 49, 905: 49, 913: 49, 914: 49, 896: 49, 899: 49, 900: 49, 883: 49, 885: 49, 887: 49, 888: 49, 871: 49, 878: 49, 284: 49, 285: 49, 286: 49, 260: 49, 262: 49, 267: 49, 350: 49, 352: 49, 353: 49, 354: 49, 337: 49, 340: 49, 343: 49, 344: 49, 95: 49, 96: 49, 97: 49, 869: 49, 85: 49, 89: 49, 71: 49, 72: 49, 73: 49, 75: 49, 76: 49, 77: 49, 78: 49, 79: 49, 862: 49, 866: 49, 68: 49, 69: 49, 70: 49, 389: 49, 390: 49, 392: 49, 395: 49, 401: 49, 382: 49, 383: 49, 370: 49, 288: 49, 360: 49, 362: 49, 850: 49, 851: 49, 855: 49, 859: 49, 841: 49, 846: 49, 847: 49, 848: 49, 824: 49, 825: 49, 839: 49, 814: 49, 816: 49, 817: 49, 818: 49, 820: 49, 821: 49, 822: 49, 823: 49, 436: 49, 437: 49, 438: 49, 440: 49, 441: 49, 425: 49, 426: 49, 427: 49, 428: 49, 429: 49, 432: 49, 421: 49, 424: 49, 402: 49, 405: 49, 407: 49, 409: 49, 410: 49, 412: 49, 807: 49, 808: 49, 809: 49, 812: 49, 791: 49, 801: 49, 802: 49, 785: 49, 787: 49, 788: 49, 789: 49, 772: 49, 773: 49, 256: 49, 452: 49, 455: 49, 458: 49, 248: 49, 249: 49, 252: 49, 253: 49, 230: 49, 232: 49, 234: 49, 238: 49, 240: 49, 450: 49, 227: 49, 228: 49, 117: 49, 120: 49, 121: 49, 125: 49, 110: 49, 111: 49, 113: 49, 116: 49, 99: 49, 100: 49, 103: 49, 108: 49, 758: 49, 760: 49, 762: 49, 763: 49, 764: 49, 767: 49, 768: 49, 204: 49, 205: 49, 482: 49, 197: 49, 198: 49, 200: 49, 201: 49, 470: 49, 471: 49, 474: 49, 476: 49, 478: 49, 479: 49, 460: 49, 464: 49, 465: 49, 466: 49, 467: 49, 746: 49, 749: 49, 754: 49, 755: 49, 757: 49, 736: 49, 739: 49, 741: 49, 743: 49, 744: 49, 745: 49, 722: 49, 726: 49, 727: 49, 730: 49, 711: 49, 719: 49, 509: 49, 510: 49, 518: 49, 519: 49, 495: 49, 504: 49, 508: 49, 483: 49, 488: 49, 212: 49, 216: 49, 219: 49, 220: 49, 223: 49, 224: 49, 161: 49, 162: 49, 707: 49, 708: 49, 709: 49, 151: 49, 152: 49, 155: 49, 138: 49, 140: 49, 141: 49, 142: 49, 143: 49, 147: 49, 704: 49, 705: 49, 131: 49, 136: 49, 549: 49, 553: 49, 555: 49, 540: 49, 541: 49, 545: 49, 548: 49, 529: 49, 530: 49, 532: 49, 534: 49, 536: 49, 538: 49, 522: 49, 526: 49, 527: 49, 528: 49, 188: 49, 189: 49, 191: 49, 165: 49, 173: 49, 180: 49, 182: 49, 570: 49, 572: 49, 163: 49, 164: 49, 564: 49, 565: 49, 692: 49, 698: 49, 700: 49, 682: 49, 685: 49, 686: 49, 689: 49, 673: 49, 675: 49, 679: 49, 668: 49, 669: 49, 670: 49, 654: 49, 656: 49, 657: 49, 658: 49, 640: 49, 641: 49, 642: 49, 644: 49, 634: 49, 638: 49, 639: 49, 618: 49, 619: 49, 622: 49, 623: 49, 626: 49, 630: 49, 609: 49, 614: 49, 615: 49, 617: 49, 599: 49, 600: 49, 603: 49, 604: 49, 606: 49, 588: 49, 589: 49, 593: 49, 594: 49, 193: 49, 581: 49, 582: 49, 584: 49, 585: 49, 961: 49, 996: 49, 949: 49, 951: 49, 953: 49, 956: 49, 942: 49, 944: 49, 945: 49, 948: 49, 63: 49, 64: 49, 931: 49, 933: 49, 935: 49, 984: 49, 989: 49, 991: 49, 972: 49, 978: 49, 979: 49, 981: 49, 24: 49, 33: 49, 965: 49, 966: 49, 16: 49, 17: 49, 20: 49, 22: 49, 23: 49, 55: 48, 891: 48, 901: 48, 908: 48, 909: 48, 910: 48, 911: 48, 877: 48, 879: 48, 881: 48, 884: 48, 886: 48, 889: 48, 272: 48, 278: 48, 280: 48, 870: 48, 872: 48, 875: 48, 349: 48, 259: 48, 261: 48, 263: 48, 264: 48, 265: 48, 269: 48, 649: 48, 652: 48, 655: 48, 659: 48, 660: 48, 661: 48, 664: 48, 666: 48, 632: 48, 633: 48, 635: 48, 643: 48, 645: 48, 648: 48, 602: 48, 605: 48, 607: 48, 611: 48, 613: 48, 629: 48, 194: 48, 591: 48, 597: 48, 575: 48, 577: 48, 167: 48, 169: 48, 175: 48, 177: 48, 184: 48, 185: 48, 560: 48, 568: 48, 569: 48, 571: 48, 573: 48, 688: 48, 695: 48, 696: 48, 697: 48, 699: 48, 667: 48, 672: 48, 677: 48, 680: 48, 683: 48, 148: 48, 149: 48, 150: 48, 154: 48, 156: 48, 160: 48, 556: 48, 557: 48, 706: 48, 132: 48, 134: 48, 137: 48, 144: 48, 539: 48, 542: 48, 544: 48, 546: 48, 550: 48, 551: 48, 552: 48, 186: 48, 187: 48, 190: 48, 520: 48, 521: 48, 524: 48, 731: 48, 732: 48, 735: 48, 737: 48, 738: 48, 752: 48, 517: 48, 714: 48, 720: 48, 721: 48, 496: 48, 500: 48, 507: 48, 513: 48, 515: 48, 516: 48, 215: 48, 218: 48, 490: 48, 491: 48, 492: 48, 493: 48, 94: 48, 335: 48, 339: 48, 341: 48, 342: 48, 346: 48, 347: 48, 90: 48, 92: 48, 93: 48, 388: 48, 864: 48, 865: 48, 67: 48, 368: 48, 371: 48, 373: 48, 377: 48, 380: 48, 385: 48, 123: 48, 124: 48, 126: 48, 446: 48, 447: 48, 102: 48, 104: 48, 105: 48, 112: 48, 122: 48, 202: 48, 203: 48, 206: 48, 207: 48, 208: 48, 209: 48, 770: 48, 101: 48, 462: 48, 469: 48, 480: 48, 481: 48, 195: 48, 799: 48, 800: 48, 803: 48, 806: 48, 810: 48, 813: 48, 403: 48, 406: 48, 780: 48, 790: 48, 793: 48, 255: 48, 257: 48, 258: 48, 127: 48, 128: 48, 774: 48, 775: 48, 776: 48, 233: 48, 237: 48, 241: 48, 244: 48, 246: 48, 251: 48, 287: 48, 363: 48, 364: 48, 367: 48, 843: 48, 849: 48, 856: 48, 858: 48, 861: 48, 443: 48, 826: 48, 833: 48, 836: 48, 838: 48, 414: 48, 418: 48, 419: 48, 422: 48, 431: 48, 434: 48, 35: 48, 40: 48, 41: 48, 44: 48, 50: 48, 51: 48, 330: 48, 919: 48, 928: 48, 929: 48, 313: 48, 319: 48, 325: 48, 326: 48, 329: 48, 296: 48, 298: 48, 299: 48, 302: 48, 305: 48, 308: 48, 311: 48, 954: 48, 955: 48, 958: 48, 995: 48, 2: 48, 939: 48, 946: 48, 950: 48, 952: 48, 985: 48, 986: 48, 992: 48, 13: 48, 32: 48, 968: 48, 970: 48, 907: 47, 15: 47, 25: 47, 579: 47, 583: 47, 586: 47, 592: 47, 608: 47, 628: 47, 938: 47, 940: 47, 962: 47, 998: 47, 11: 47, 294: 47, 315: 47, 317: 47, 334: 47, 917: 47, 920: 47, 930: 47, 39: 47, 52: 47, 416: 47, 417: 47, 439: 47, 840: 47, 842: 47, 844: 47, 845: 47, 357: 47, 358: 47, 366: 47, 777: 47, 782: 47, 678: 47, 690: 47, 691: 47, 703: 47, 561: 47, 567: 47, 795: 47, 796: 47, 461: 47, 477: 47, 114: 47, 115: 47, 448: 47, 229: 47, 375: 47, 387: 47, 394: 47, 398: 47, 400: 47, 82: 47, 83: 47, 86: 47, 87: 47, 88: 47, 867: 47, 498: 47, 712: 47, 715: 47, 718: 47, 747: 47, 756: 47, 523: 47, 531: 47, 547: 47, 135: 47, 153: 47, 674: 47, 268: 47, 273: 47, 874: 47, 876: 47, 890: 47, 897: 47, 964: 47, 975: 47, 976: 47, 983: 47, 987: 47, 59: 47, 65: 47, 58: 46, 636: 46, 28: 46, 158: 46, 489: 46, 494: 46, 723: 46, 225: 46, 449: 46, 384: 46, 472: 46, 109: 46, 681: 46, 559: 46, 239: 46, 254: 46, 778: 46, 435: 46, 328: 46, 601: 46, 53: 46, 355: 45, 631: 45, 12: 45}\n",
      "cluster #1\n",
      "accuracy: 0.60 (30/50)\n",
      "prediction: {46: 1, 44: 1, 67: 1, 69: 1, 83: 1, 93: 1, 109: 1, 132: 1, 182: 1, 186: 1, 194: 1, 183: 1, 241: 1, 253: 1, 287: 1, 368: 1, 313: 1, 325: 1, 330: 1, 382: 1, 417: 1, 478: 1, 844: 1, 527: 1, 548: 1, 571: 1, 887: 1, 673: 1, 632: 1, 683: 1, 690: 1, 707: 1, 722: 1, 746: 1, 755: 1, 762: 1, 763: 1, 780: 1, 515: 1, 823: 1, 843: 1, 845: 1, 785: 1, 822: 1, 935: 1, 950: 1, 941: 1, 961: 1, 698: 1, 987: 1}\n",
      "label: {964: 2, 44: 1, 67: 1, 69: 1, 83: 1, 93: 1, 109: 1, 134: 1, 182: 1, 184: 1, 194: 1, 197: 1, 240: 1, 253: 1, 287: 1, 299: 1, 40: 1, 308: 1, 325: 1, 380: 1, 330: 1, 478: 1, 507: 1, 508: 1, 417: 1, 571: 1, 601: 1, 622: 1, 632: 1, 683: 1, 690: 1, 707: 1, 548: 1, 722: 1, 746: 1, 762: 1, 755: 1, 780: 1, 808: 1, 823: 1, 763: 1, 843: 1, 845: 1, 909: 1, 885: 1, 942: 1, 950: 1, 975: 1, 998: 1}\n",
      "cluster #2\n",
      "accuracy: 0.66 (33/50)\n",
      "prediction: {15: 1, 20: 1, 50: 1, 55: 1, 64: 1, 82: 1, 83: 1, 85: 1, 89: 1, 502: 1, 132: 1, 163: 1, 198: 1, 218: 1, 220: 1, 225: 1, 232: 1, 308: 1, 326: 1, 973: 1, 334: 1, 366: 1, 371: 1, 403: 1, 285: 1, 439: 1, 443: 1, 514: 1, 462: 1, 456: 1, 782: 1, 540: 1, 620: 1, 601: 1, 644: 1, 918: 1, 680: 1, 716: 1, 424: 1, 774: 1, 800: 1, 801: 1, 803: 1, 868: 1, 700: 1, 468: 1, 850: 1, 530: 1, 905: 1, 992: 1}\n",
      "label: {15: 1, 20: 1, 50: 1, 59: 1, 64: 1, 82: 1, 83: 1, 85: 1, 89: 1, 117: 1, 132: 1, 163: 1, 198: 1, 218: 1, 220: 1, 225: 1, 232: 1, 308: 1, 326: 1, 328: 1, 334: 1, 366: 1, 371: 1, 403: 1, 431: 1, 439: 1, 443: 1, 461: 1, 462: 1, 524: 1, 527: 1, 540: 1, 551: 1, 601: 1, 632: 1, 673: 1, 680: 1, 703: 1, 735: 1, 774: 1, 800: 1, 801: 1, 803: 1, 809: 1, 838: 1, 864: 1, 865: 1, 897: 1, 905: 1, 992: 1}\n",
      "cluster #3\n",
      "accuracy: 0.68 (34/50)\n",
      "prediction: {412: 2, 41: 1, 43: 1, 47: 1, 58: 1, 59: 1, 921: 1, 113: 1, 124: 1, 132: 1, 140: 1, 186: 1, 155: 1, 194: 1, 292: 1, 335: 1, 28: 1, 353: 1, 407: 1, 452: 1, 489: 1, 494: 1, 608: 1, 532: 1, 819: 1, 575: 1, 560: 1, 589: 1, 626: 1, 818: 1, 739: 1, 672: 1, 715: 1, 718: 1, 747: 1, 645: 1, 563: 1, 806: 1, 825: 1, 838: 1, 881: 1, 850: 1, 504: 1, 929: 1, 930: 1, 976: 1, 983: 1, 984: 1, 935: 1}\n",
      "label: {28: 1, 41: 1, 43: 1, 47: 1, 58: 1, 59: 1, 99: 1, 113: 1, 124: 1, 132: 1, 140: 1, 186: 1, 200: 1, 202: 1, 292: 1, 335: 1, 352: 1, 407: 1, 412: 1, 452: 1, 461: 1, 489: 1, 494: 1, 523: 1, 532: 1, 546: 1, 559: 1, 560: 1, 589: 1, 629: 1, 633: 1, 666: 1, 672: 1, 715: 1, 718: 1, 747: 1, 775: 1, 777: 1, 806: 1, 825: 1, 838: 1, 881: 1, 911: 1, 928: 1, 929: 1, 930: 1, 976: 1, 983: 1, 984: 1, 987: 1}\n",
      "cluster #4\n",
      "accuracy: 0.78 (39/50)\n",
      "prediction: {816: 2, 796: 2, 1: 1, 12: 1, 88: 1, 116: 1, 24: 1, 35: 1, 165: 1, 189: 1, 192: 1, 238: 1, 268: 1, 334: 1, 122: 1, 150: 1, 383: 1, 344: 1, 6: 1, 466: 1, 513: 1, 520: 1, 467: 1, 481: 1, 564: 1, 497: 1, 659: 1, 668: 1, 880: 1, 459: 1, 526: 1, 553: 1, 690: 1, 570: 1, 695: 1, 721: 1, 778: 1, 776: 1, 789: 1, 814: 1, 819: 1, 826: 1, 862: 1, 918: 1, 920: 1, 939: 1, 952: 1, 986: 1}\n",
      "label: {796: 2, 12: 1, 24: 1, 35: 1, 88: 1, 116: 1, 122: 1, 150: 1, 165: 1, 189: 1, 203: 1, 241: 1, 268: 1, 334: 1, 344: 1, 383: 1, 1: 1, 395: 1, 421: 1, 482: 1, 467: 1, 520: 1, 526: 1, 553: 1, 513: 1, 607: 1, 659: 1, 668: 1, 675: 1, 678: 1, 680: 1, 690: 1, 564: 1, 695: 1, 721: 1, 778: 1, 776: 1, 789: 1, 814: 1, 816: 1, 822: 1, 826: 1, 862: 1, 911: 1, 918: 1, 920: 1, 939: 1, 952: 1, 986: 1}\n",
      "cluster #5\n",
      "accuracy: 0.66 (33/50)\n",
      "prediction: {998: 2, 13: 1, 25: 1, 33: 1, 39: 1, 53: 1, 90: 1, 111: 1, 346: 1, 237: 1, 169: 1, 222: 1, 223: 1, 286: 1, 310: 1, 313: 1, 8: 1, 341: 1, 343: 1, 362: 1, 355: 1, 373: 1, 334: 1, 380: 1, 368: 1, 471: 1, 732: 1, 483: 1, 489: 1, 491: 1, 518: 1, 573: 1, 434: 1, 826: 1, 652: 1, 442: 1, 580: 1, 721: 1, 772: 1, 755: 1, 691: 1, 785: 1, 794: 1, 908: 1, 845: 1, 922: 1, 952: 1, 961: 1, 936: 1}\n",
      "label: {273: 2, 7: 1, 13: 1, 33: 1, 25: 1, 53: 1, 90: 1, 111: 1, 39: 1, 128: 1, 158: 1, 169: 1, 257: 1, 310: 1, 313: 1, 341: 1, 343: 1, 355: 1, 358: 1, 368: 1, 373: 1, 377: 1, 380: 1, 434: 1, 471: 1, 477: 1, 483: 1, 489: 1, 491: 1, 518: 1, 573: 1, 635: 1, 652: 1, 660: 1, 682: 1, 691: 1, 721: 1, 772: 1, 807: 1, 836: 1, 844: 1, 845: 1, 908: 1, 922: 1, 952: 1, 961: 1, 979: 1, 987: 1, 998: 1}\n",
      "cluster #6\n",
      "accuracy: 0.74 (37/50)\n",
      "prediction: {49: 2, 4: 1, 12: 1, 28: 1, 59: 1, 87: 1, 95: 1, 97: 1, 124: 1, 127: 1, 135: 1, 148: 1, 164: 1, 177: 1, 187: 1, 204: 1, 234: 1, 215: 1, 244: 1, 252: 1, 291: 1, 301: 1, 348: 1, 357: 1, 377: 1, 477: 1, 419: 1, 429: 1, 498: 1, 519: 1, 402: 1, 584: 1, 586: 1, 963: 1, 649: 1, 661: 1, 526: 1, 703: 1, 712: 1, 723: 1, 770: 1, 457: 1, 891: 1, 895: 1, 926: 1, 948: 1, 964: 1, 618: 1, 992: 1}\n",
      "label: {4: 1, 12: 1, 28: 1, 65: 1, 67: 1, 87: 1, 95: 1, 97: 1, 124: 1, 127: 1, 135: 1, 148: 1, 175: 1, 177: 1, 187: 1, 204: 1, 208: 1, 215: 1, 244: 1, 252: 1, 291: 1, 301: 1, 349: 1, 353: 1, 357: 1, 377: 1, 418: 1, 419: 1, 429: 1, 498: 1, 519: 1, 546: 1, 584: 1, 586: 1, 614: 1, 649: 1, 661: 1, 664: 1, 703: 1, 712: 1, 723: 1, 770: 1, 841: 1, 891: 1, 908: 1, 926: 1, 948: 1, 964: 1, 968: 1, 992: 1}\n",
      "cluster #7\n",
      "accuracy: 0.54 (27/50)\n",
      "prediction: {239: 2, 185: 2, 19: 1, 25: 1, 135: 1, 149: 1, 331: 1, 105: 1, 201: 1, 155: 1, 218: 1, 151: 1, 230: 1, 181: 1, 307: 1, 319: 1, 360: 1, 364: 1, 402: 1, 447: 1, 840: 1, 589: 1, 517: 1, 521: 1, 531: 1, 557: 1, 602: 1, 628: 1, 838: 1, 706: 1, 894: 1, 678: 1, 681: 1, 691: 1, 718: 1, 780: 1, 910: 1, 967: 1, 743: 1, 886: 1, 581: 1, 692: 1, 637: 1, 321: 1, 100: 1, 972: 1, 976: 1, 998: 1}\n",
      "label: {154: 2, 239: 2, 976: 2, 946: 2, 557: 2, 135: 1, 105: 1, 158: 1, 149: 1, 185: 1, 83: 1, 25: 1, 12: 1, 230: 1, 218: 1, 191: 1, 265: 1, 364: 1, 402: 1, 319: 1, 311: 1, 462: 1, 477: 1, 521: 1, 517: 1, 531: 1, 628: 1, 447: 1, 360: 1, 634: 1, 631: 1, 648: 1, 678: 1, 718: 1, 780: 1, 681: 1, 691: 1, 855: 1, 813: 1, 865: 1, 886: 1, 921: 1, 920: 1, 975: 1, 998: 1}\n",
      "cluster #8\n",
      "accuracy: 0.76 (38/50)\n",
      "prediction: {115: 2, 5: 1, 13: 1, 51: 1, 35: 1, 59: 1, 463: 1, 109: 1, 142: 1, 149: 1, 216: 1, 239: 1, 348: 1, 278: 1, 298: 1, 315: 1, 319: 1, 328: 1, 331: 1, 355: 1, 359: 1, 364: 1, 388: 1, 401: 1, 636: 1, 450: 1, 481: 1, 507: 1, 454: 1, 510: 1, 577: 1, 603: 1, 648: 1, 667: 1, 685: 1, 688: 1, 711: 1, 732: 1, 756: 1, 774: 1, 968: 1, 861: 1, 706: 1, 886: 1, 412: 1, 901: 1, 692: 1, 940: 1, 991: 1}\n",
      "label: {115: 2, 5: 1, 13: 1, 51: 1, 37: 1, 59: 1, 94: 1, 109: 1, 142: 1, 147: 1, 216: 1, 239: 1, 257: 1, 278: 1, 298: 1, 315: 1, 319: 1, 328: 1, 330: 1, 355: 1, 358: 1, 364: 1, 388: 1, 401: 1, 414: 1, 450: 1, 481: 1, 507: 1, 509: 1, 510: 1, 577: 1, 603: 1, 648: 1, 667: 1, 685: 1, 688: 1, 711: 1, 732: 1, 756: 1, 774: 1, 818: 1, 861: 1, 876: 1, 886: 1, 900: 1, 901: 1, 917: 1, 940: 1, 991: 1}\n",
      "cluster #9\n",
      "accuracy: 0.68 (34/50)\n",
      "prediction: {237: 2, 605: 2, 803: 2, 138: 1, 185: 1, 75: 1, 56: 1, 195: 1, 202: 1, 208: 1, 225: 1, 251: 1, 284: 1, 194: 1, 991: 1, 205: 1, 357: 1, 368: 1, 390: 1, 696: 1, 736: 1, 394: 1, 449: 1, 461: 1, 670: 1, 528: 1, 539: 1, 686: 1, 542: 1, 560: 1, 578: 1, 608: 1, 667: 1, 679: 1, 855: 1, 739: 1, 743: 1, 752: 1, 773: 1, 774: 1, 845: 1, 872: 1, 161: 1, 821: 1, 889: 1, 926: 1, 940: 1}\n",
      "label: {237: 2, 605: 2, 114: 1, 56: 1, 186: 1, 194: 1, 195: 1, 75: 1, 202: 1, 208: 1, 225: 1, 246: 1, 284: 1, 357: 1, 367: 1, 138: 1, 368: 1, 390: 1, 449: 1, 394: 1, 470: 1, 516: 1, 524: 1, 455: 1, 528: 1, 539: 1, 551: 1, 542: 1, 560: 1, 561: 1, 601: 1, 608: 1, 667: 1, 679: 1, 686: 1, 739: 1, 743: 1, 752: 1, 773: 1, 790: 1, 803: 1, 845: 1, 872: 1, 883: 1, 884: 1, 889: 1, 909: 1, 940: 1}\n",
      "cluster #10\n",
      "accuracy: 0.74 (37/50)\n",
      "prediction: {328: 2, 16: 1, 52: 1, 76: 1, 310: 1, 93: 1, 155: 1, 184: 1, 79: 1, 233: 1, 294: 1, 315: 1, 313: 1, 170: 1, 384: 1, 884: 1, 416: 1, 437: 1, 438: 1, 441: 1, 926: 1, 476: 1, 480: 1, 531: 1, 547: 1, 559: 1, 284: 1, 570: 1, 599: 1, 608: 1, 630: 1, 659: 1, 670: 1, 674: 1, 761: 1, 776: 1, 697: 1, 775: 1, 845: 1, 886: 1, 877: 1, 619: 1, 889: 1, 896: 1, 917: 1, 920: 1, 965: 1, 955: 1, 985: 1}\n",
      "label: {328: 2, 16: 1, 52: 1, 76: 1, 71: 1, 93: 1, 155: 1, 184: 1, 79: 1, 233: 1, 294: 1, 311: 1, 313: 1, 341: 1, 384: 1, 406: 1, 416: 1, 437: 1, 438: 1, 441: 1, 469: 1, 476: 1, 480: 1, 531: 1, 547: 1, 559: 1, 568: 1, 577: 1, 599: 1, 608: 1, 630: 1, 659: 1, 670: 1, 674: 1, 681: 1, 683: 1, 697: 1, 775: 1, 776: 1, 790: 1, 877: 1, 887: 1, 889: 1, 896: 1, 917: 1, 920: 1, 930: 1, 955: 1, 985: 1}\n",
      "cluster #11\n",
      "accuracy: 0.72 (36/50)\n",
      "prediction: {583: 2, 15: 1, 53: 1, 64: 1, 86: 1, 88: 1, 94: 1, 104: 1, 965: 1, 310: 1, 131: 1, 137: 1, 187: 1, 159: 1, 249: 1, 267: 1, 2: 1, 299: 1, 302: 1, 342: 1, 329: 1, 366: 1, 375: 1, 394: 1, 356: 1, 400: 1, 432: 1, 876: 1, 477: 1, 591: 1, 558: 1, 613: 1, 628: 1, 631: 1, 635: 1, 636: 1, 811: 1, 51: 1, 688: 1, 720: 1, 731: 1, 736: 1, 487: 1, 800: 1, 462: 1, 890: 1, 933: 1, 966: 1, 986: 1}\n",
      "label: {583: 2, 15: 1, 53: 1, 55: 1, 82: 1, 88: 1, 94: 1, 104: 1, 121: 1, 126: 1, 131: 1, 137: 1, 203: 1, 209: 1, 248: 1, 267: 1, 2: 1, 299: 1, 302: 1, 342: 1, 329: 1, 366: 1, 375: 1, 394: 1, 358: 1, 400: 1, 432: 1, 434: 1, 477: 1, 591: 1, 593: 1, 613: 1, 628: 1, 631: 1, 635: 1, 636: 1, 640: 1, 643: 1, 688: 1, 720: 1, 731: 1, 736: 1, 785: 1, 800: 1, 840: 1, 890: 1, 933: 1, 966: 1, 986: 1}\n",
      "cluster #12\n",
      "accuracy: 0.84 (42/50)\n",
      "prediction: {103: 2, 22: 1, 46: 1, 51: 1, 112: 1, 148: 1, 206: 1, 219: 1, 259: 1, 264: 1, 295: 1, 325: 1, 970: 1, 355: 1, 363: 1, 382: 1, 384: 1, 385: 1, 416: 1, 417: 1, 424: 1, 472: 1, 493: 1, 520: 1, 541: 1, 544: 1, 547: 1, 552: 1, 569: 1, 572: 1, 579: 1, 655: 1, 672: 1, 620: 1, 715: 1, 447: 1, 719: 1, 720: 1, 754: 1, 855: 1, 770: 1, 810: 1, 820: 1, 575: 1, 717: 1, 874: 1, 884: 1, 907: 1, 975: 1}\n",
      "label: {22: 1, 35: 1, 46: 1, 51: 1, 103: 1, 112: 1, 148: 1, 206: 1, 219: 1, 259: 1, 264: 1, 297: 1, 325: 1, 349: 1, 355: 1, 363: 1, 382: 1, 384: 1, 385: 1, 416: 1, 417: 1, 424: 1, 472: 1, 493: 1, 520: 1, 541: 1, 544: 1, 547: 1, 552: 1, 569: 1, 572: 1, 579: 1, 655: 1, 672: 1, 681: 1, 715: 1, 718: 1, 719: 1, 720: 1, 754: 1, 767: 1, 770: 1, 810: 1, 820: 1, 866: 1, 870: 1, 874: 1, 884: 1, 907: 1, 975: 1}\n",
      "cluster #13\n",
      "accuracy: 0.76 (38/50)\n",
      "prediction: {8: 1, 25: 1, 46: 1, 6: 1, 120: 1, 122: 1, 141: 1, 144: 1, 158: 1, 160: 1, 173: 1, 175: 1, 229: 1, 246: 1, 251: 1, 255: 1, 259: 1, 261: 1, 269: 1, 296: 1, 360: 1, 410: 1, 427: 1, 469: 1, 527: 1, 494: 1, 495: 1, 439: 1, 999: 1, 446: 1, 845: 1, 656: 1, 586: 1, 602: 1, 615: 1, 645: 1, 436: 1, 664: 1, 692: 1, 464: 1, 737: 1, 744: 1, 749: 1, 810: 1, 856: 1, 867: 1, 828: 1, 938: 1, 965: 1, 983: 1}\n",
      "label: {8: 1, 25: 1, 40: 1, 58: 1, 120: 1, 122: 1, 141: 1, 144: 1, 158: 1, 160: 1, 173: 1, 175: 1, 229: 1, 246: 1, 251: 1, 255: 1, 259: 1, 261: 1, 269: 1, 296: 1, 357: 1, 410: 1, 427: 1, 469: 1, 481: 1, 494: 1, 495: 1, 513: 1, 529: 1, 549: 1, 550: 1, 581: 1, 586: 1, 602: 1, 615: 1, 645: 1, 656: 1, 664: 1, 692: 1, 714: 1, 737: 1, 744: 1, 749: 1, 810: 1, 856: 1, 867: 1, 928: 1, 938: 1, 965: 1, 983: 1}\n",
      "cluster #14\n",
      "accuracy: 0.62 (31/50)\n",
      "prediction: {32: 1, 76: 1, 78: 1, 92: 1, 127: 1, 234: 1, 254: 1, 258: 1, 225: 1, 180: 1, 287: 1, 296: 1, 315: 1, 317: 1, 343: 1, 355: 1, 398: 1, 422: 1, 479: 1, 816: 1, 912: 1, 839: 1, 598: 1, 529: 1, 517: 1, 539: 1, 559: 1, 728: 1, 579: 1, 597: 1, 772: 1, 604: 1, 629: 1, 641: 1, 601: 1, 699: 1, 745: 1, 760: 1, 778: 1, 851: 1, 795: 1, 844: 1, 725: 1, 870: 1, 513: 1, 88: 1, 891: 1, 966: 1, 909: 1, 987: 1}\n",
      "label: {559: 2, 77: 1, 78: 1, 92: 1, 127: 1, 234: 1, 254: 1, 258: 1, 262: 1, 268: 1, 287: 1, 296: 1, 315: 1, 317: 1, 342: 1, 355: 1, 32: 1, 398: 1, 422: 1, 446: 1, 436: 1, 472: 1, 498: 1, 516: 1, 449: 1, 517: 1, 539: 1, 579: 1, 597: 1, 600: 1, 604: 1, 629: 1, 641: 1, 689: 1, 699: 1, 745: 1, 760: 1, 778: 1, 782: 1, 795: 1, 844: 1, 849: 1, 870: 1, 875: 1, 879: 1, 891: 1, 907: 1, 910: 1, 987: 1}\n",
      "cluster #15\n",
      "accuracy: 0.76 (38/50)\n",
      "prediction: {317: 2, 44: 1, 38: 1, 57: 1, 82: 1, 86: 1, 108: 1, 115: 1, 121: 1, 137: 1, 151: 1, 185: 1, 195: 1, 233: 1, 268: 1, 253: 1, 12: 1, 294: 1, 318: 1, 320: 1, 355: 1, 383: 1, 389: 1, 417: 1, 719: 1, 474: 1, 782: 1, 523: 1, 568: 1, 575: 1, 588: 1, 611: 1, 652: 1, 674: 1, 690: 1, 697: 1, 712: 1, 715: 1, 726: 1, 727: 1, 186: 1, 902: 1, 787: 1, 839: 1, 858: 1, 738: 1, 867: 1, 879: 1, 945: 1}\n",
      "label: {86: 2, 317: 2, 54: 1, 12: 1, 57: 1, 108: 1, 115: 1, 44: 1, 137: 1, 151: 1, 185: 1, 195: 1, 233: 1, 268: 1, 273: 1, 125: 1, 294: 1, 318: 1, 320: 1, 355: 1, 362: 1, 389: 1, 417: 1, 443: 1, 474: 1, 480: 1, 523: 1, 568: 1, 575: 1, 588: 1, 611: 1, 652: 1, 677: 1, 690: 1, 697: 1, 712: 1, 715: 1, 726: 1, 727: 1, 738: 1, 758: 1, 787: 1, 839: 1, 858: 1, 861: 1, 867: 1, 879: 1, 949: 1}\n",
      "cluster #16\n",
      "accuracy: 0.56 (28/50)\n",
      "prediction: {254: 2, 305: 2, 448: 2, 963: 1, 144: 1, 48: 1, 26: 1, 215: 1, 360: 1, 225: 1, 335: 1, 336: 1, 369: 1, 386: 1, 87: 1, 387: 1, 398: 1, 465: 1, 488: 1, 490: 1, 575: 1, 592: 1, 400: 1, 801: 1, 628: 1, 636: 1, 543: 1, 696: 1, 655: 1, 920: 1, 528: 1, 469: 1, 527: 1, 424: 1, 833: 1, 505: 1, 864: 1, 890: 1, 871: 1, 917: 1, 919: 1, 964: 1, 940: 1, 580: 1, 962: 1, 979: 1, 995: 1}\n",
      "label: {254: 2, 305: 2, 490: 2, 448: 2, 87: 1, 112: 1, 150: 1, 144: 1, 225: 1, 215: 1, 335: 1, 337: 1, 41: 1, 52: 1, 385: 1, 367: 1, 398: 1, 387: 1, 465: 1, 575: 1, 592: 1, 606: 1, 623: 1, 628: 1, 636: 1, 674: 1, 696: 1, 730: 1, 747: 1, 768: 1, 778: 1, 782: 1, 793: 1, 833: 1, 849: 1, 864: 1, 890: 1, 914: 1, 917: 1, 919: 1, 935: 1, 940: 1, 953: 1, 962: 1, 970: 1, 995: 1}\n",
      "cluster #17\n",
      "accuracy: 0.48 (24/50)\n",
      "prediction: {187: 2, 876: 2, 52: 1, 28: 1, 101: 1, 86: 1, 109: 1, 39: 1, 600: 1, 161: 1, 177: 1, 180: 1, 238: 1, 234: 1, 281: 1, 88: 1, 78: 1, 313: 1, 381: 1, 843: 1, 419: 1, 703: 1, 601: 1, 868: 1, 631: 1, 638: 1, 734: 1, 508: 1, 787: 1, 920: 1, 705: 1, 721: 1, 723: 1, 775: 1, 802: 1, 630: 1, 745: 1, 847: 1, 858: 1, 878: 1, 897: 1, 925: 1, 948: 1, 923: 1, 970: 1, 979: 1, 989: 1, 996: 1}\n",
      "label: {435: 2, 39: 1, 52: 1, 88: 1, 101: 1, 104: 1, 109: 1, 114: 1, 161: 1, 177: 1, 180: 1, 193: 1, 201: 1, 238: 1, 260: 1, 285: 1, 28: 1, 314: 1, 315: 1, 384: 1, 339: 1, 419: 1, 488: 1, 601: 1, 626: 1, 631: 1, 639: 1, 654: 1, 681: 1, 695: 1, 704: 1, 705: 1, 709: 1, 723: 1, 735: 1, 802: 1, 806: 1, 844: 1, 847: 1, 858: 1, 878: 1, 897: 1, 925: 1, 954: 1, 962: 1, 970: 1, 972: 1, 989: 1, 996: 1}\n",
      "cluster #18\n",
      "accuracy: 0.74 (37/50)\n",
      "prediction: {190: 2, 2: 1, 13: 1, 68: 1, 38: 1, 105: 1, 123: 1, 124: 1, 87: 1, 126: 1, 153: 1, 156: 1, 227: 1, 256: 1, 280: 1, 288: 1, 323: 1, 340: 1, 346: 1, 354: 1, 363: 1, 370: 1, 381: 1, 394: 1, 685: 1, 449: 1, 466: 1, 367: 1, 504: 1, 531: 1, 544: 1, 659: 1, 867: 1, 565: 1, 571: 1, 613: 1, 643: 1, 644: 1, 655: 1, 699: 1, 723: 1, 860: 1, 793: 1, 795: 1, 840: 1, 876: 1, 897: 1, 696: 1, 950: 1}\n",
      "label: {123: 2, 153: 2, 38: 1, 2: 1, 68: 1, 87: 1, 105: 1, 23: 1, 126: 1, 156: 1, 190: 1, 227: 1, 256: 1, 272: 1, 288: 1, 323: 1, 340: 1, 346: 1, 354: 1, 363: 1, 371: 1, 384: 1, 394: 1, 409: 1, 449: 1, 466: 1, 491: 1, 504: 1, 530: 1, 544: 1, 550: 1, 561: 1, 565: 1, 571: 1, 613: 1, 643: 1, 644: 1, 655: 1, 699: 1, 723: 1, 764: 1, 793: 1, 795: 1, 840: 1, 876: 1, 897: 1, 907: 1, 950: 1}\n",
      "cluster #19\n",
      "accuracy: 0.72 (36/50)\n",
      "prediction: {757: 2, 958: 2, 28: 1, 37: 1, 38: 1, 92: 1, 39: 1, 288: 1, 134: 1, 162: 1, 169: 1, 205: 1, 228: 1, 260: 1, 102: 1, 128: 1, 269: 1, 263: 1, 286: 1, 387: 1, 876: 1, 448: 1, 388: 1, 602: 1, 492: 1, 530: 1, 534: 1, 547: 1, 597: 1, 618: 1, 472: 1, 479: 1, 658: 1, 642: 1, 476: 1, 892: 1, 708: 1, 777: 1, 861: 1, 698: 1, 859: 1, 797: 1, 541: 1, 872: 1, 877: 1, 931: 1, 939: 1, 962: 1}\n",
      "label: {958: 2, 36: 1, 39: 1, 45: 1, 58: 1, 92: 1, 102: 1, 128: 1, 134: 1, 167: 1, 169: 1, 205: 1, 228: 1, 258: 1, 263: 1, 269: 1, 28: 1, 286: 1, 387: 1, 416: 1, 388: 1, 448: 1, 472: 1, 479: 1, 435: 1, 531: 1, 534: 1, 547: 1, 597: 1, 618: 1, 642: 1, 658: 1, 492: 1, 696: 1, 698: 1, 708: 1, 706: 1, 777: 1, 778: 1, 859: 1, 757: 1, 867: 1, 869: 1, 875: 1, 872: 1, 877: 1, 931: 1, 939: 1, 962: 1}\n",
      "cluster #20\n",
      "accuracy: 0.68 (34/50)\n",
      "prediction: {375: 2, 63: 1, 85: 1, 102: 1, 100: 1, 238: 1, 187: 1, 291: 1, 149: 1, 225: 1, 151: 1, 280: 1, 269: 1, 350: 1, 339: 1, 346: 1, 392: 1, 667: 1, 406: 1, 426: 1, 516: 1, 478: 1, 717: 1, 636: 1, 472: 1, 743: 1, 493: 1, 498: 1, 683: 1, 631: 1, 660: 1, 678: 1, 700: 1, 756: 1, 777: 1, 813: 1, 817: 1, 833: 1, 843: 1, 895: 1, 876: 1, 888: 1, 934: 1, 945: 1, 952: 1, 955: 1, 981: 1, 983: 1, 995: 1}\n",
      "label: {375: 2, 63: 1, 86: 1, 102: 1, 100: 1, 167: 1, 187: 1, 207: 1, 149: 1, 225: 1, 263: 1, 280: 1, 272: 1, 294: 1, 339: 1, 346: 1, 392: 1, 400: 1, 406: 1, 426: 1, 431: 1, 446: 1, 447: 1, 464: 1, 472: 1, 489: 1, 493: 1, 498: 1, 617: 1, 631: 1, 660: 1, 678: 1, 700: 1, 756: 1, 777: 1, 813: 1, 817: 1, 833: 1, 843: 1, 871: 1, 876: 1, 888: 1, 930: 1, 945: 1, 951: 1, 955: 1, 981: 1, 983: 1, 995: 1}\n",
      "cluster #21\n",
      "accuracy: 0.76 (38/50)\n",
      "prediction: {515: 2, 53: 1, 70: 1, 72: 1, 90: 1, 101: 1, 136: 1, 155: 1, 215: 1, 188: 1, 212: 1, 229: 1, 255: 1, 277: 1, 298: 1, 300: 1, 11: 1, 347: 1, 554: 1, 543: 1, 425: 1, 460: 1, 461: 1, 522: 1, 567: 1, 569: 1, 573: 1, 583: 1, 592: 1, 594: 1, 611: 1, 645: 1, 649: 1, 918: 1, 691: 1, 712: 1, 402: 1, 788: 1, 727: 1, 824: 1, 840: 1, 845: 1, 850: 1, 851: 1, 874: 1, 773: 1, 901: 1, 910: 1, 938: 1}\n",
      "label: {11: 1, 53: 1, 70: 1, 72: 1, 90: 1, 101: 1, 136: 1, 152: 1, 156: 1, 188: 1, 212: 1, 229: 1, 255: 1, 280: 1, 298: 1, 300: 1, 347: 1, 418: 1, 422: 1, 428: 1, 449: 1, 460: 1, 461: 1, 515: 1, 522: 1, 567: 1, 569: 1, 573: 1, 583: 1, 592: 1, 594: 1, 611: 1, 645: 1, 649: 1, 666: 1, 691: 1, 712: 1, 714: 1, 788: 1, 799: 1, 824: 1, 840: 1, 846: 1, 850: 1, 851: 1, 874: 1, 899: 1, 901: 1, 910: 1, 938: 1}\n",
      "cluster #22\n",
      "accuracy: 0.66 (33/50)\n",
      "prediction: {55: 2, 747: 2, 500: 2, 74: 1, 143: 1, 11: 1, 390: 1, 190: 1, 207: 1, 209: 1, 254: 1, 278: 1, 331: 1, 151: 1, 162: 1, 373: 1, 347: 1, 458: 1, 400: 1, 843: 1, 494: 1, 515: 1, 403: 1, 555: 1, 561: 1, 567: 1, 960: 1, 631: 1, 591: 1, 592: 1, 833: 1, 608: 1, 682: 1, 669: 1, 677: 1, 629: 1, 781: 1, 894: 1, 842: 1, 651: 1, 595: 1, 890: 1, 924: 1, 401: 1, 938: 1, 944: 1, 99: 1}\n",
      "label: {567: 2, 494: 2, 500: 2, 65: 1, 11: 1, 53: 1, 55: 1, 162: 1, 190: 1, 207: 1, 209: 1, 254: 1, 73: 1, 143: 1, 158: 1, 347: 1, 331: 1, 278: 1, 373: 1, 458: 1, 403: 1, 515: 1, 400: 1, 536: 1, 555: 1, 561: 1, 585: 1, 591: 1, 592: 1, 608: 1, 619: 1, 657: 1, 669: 1, 677: 1, 731: 1, 747: 1, 752: 1, 799: 1, 842: 1, 848: 1, 856: 1, 890: 1, 924: 1, 929: 1, 938: 1, 944: 1, 978: 1}\n",
      "cluster #23\n",
      "accuracy: 0.74 (37/50)\n",
      "prediction: {414: 2, 12: 1, 15: 1, 82: 1, 109: 1, 114: 1, 135: 1, 153: 1, 164: 1, 208: 1, 223: 1, 239: 1, 244: 1, 329: 1, 334: 1, 170: 1, 11: 1, 366: 1, 370: 1, 584: 1, 425: 1, 439: 1, 489: 1, 521: 1, 523: 1, 481: 1, 848: 1, 980: 1, 877: 1, 586: 1, 702: 1, 607: 1, 609: 1, 838: 1, 674: 1, 703: 1, 738: 1, 741: 1, 756: 1, 598: 1, 791: 1, 795: 1, 821: 1, 693: 1, 64: 1, 842: 1, 874: 1, 913: 1, 919: 1}\n",
      "label: {842: 2, 12: 1, 15: 1, 82: 1, 109: 1, 114: 1, 135: 1, 153: 1, 164: 1, 206: 1, 223: 1, 239: 1, 244: 1, 329: 1, 334: 1, 350: 1, 11: 1, 366: 1, 370: 1, 414: 1, 398: 1, 439: 1, 489: 1, 521: 1, 425: 1, 542: 1, 545: 1, 552: 1, 556: 1, 586: 1, 602: 1, 607: 1, 523: 1, 609: 1, 631: 1, 674: 1, 636: 1, 738: 1, 741: 1, 756: 1, 703: 1, 782: 1, 791: 1, 821: 1, 795: 1, 836: 1, 874: 1, 913: 1, 919: 1}\n",
      "cluster #24\n",
      "accuracy: 0.78 (39/50)\n",
      "prediction: {496: 2, 302: 2, 17: 1, 32: 1, 65: 1, 96: 1, 50: 1, 58: 1, 224: 1, 229: 1, 241: 1, 249: 1, 251: 1, 261: 1, 110: 1, 160: 1, 266: 1, 264: 1, 316: 1, 307: 1, 387: 1, 405: 1, 876: 1, 322: 1, 439: 1, 440: 1, 492: 1, 538: 1, 827: 1, 570: 1, 881: 1, 762: 1, 507: 1, 636: 1, 638: 1, 661: 1, 706: 1, 723: 1, 732: 1, 737: 1, 802: 1, 812: 1, 531: 1, 432: 1, 954: 1, 956: 1, 968: 1, 985: 1}\n",
      "label: {496: 2, 32: 1, 50: 1, 58: 1, 65: 1, 96: 1, 110: 1, 160: 1, 224: 1, 229: 1, 241: 1, 249: 1, 251: 1, 261: 1, 264: 1, 265: 1, 17: 1, 302: 1, 306: 1, 316: 1, 307: 1, 387: 1, 405: 1, 435: 1, 326: 1, 439: 1, 440: 1, 492: 1, 538: 1, 556: 1, 570: 1, 579: 1, 582: 1, 633: 1, 636: 1, 638: 1, 661: 1, 706: 1, 723: 1, 732: 1, 737: 1, 796: 1, 812: 1, 826: 1, 881: 1, 954: 1, 956: 1, 968: 1, 985: 1}\n"
     ]
    }
   ],
   "source": [
    "for displayer in displayers:\n",
    "    displayer(clusters, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define rule clusterer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _accuracy(data):\n",
    "    return (data.metadata[\"prediction_label\"] == data.metadata[\"label\"]).mean()\n",
    "\n",
    "\n",
    "def _size(data):\n",
    "    return len(data)\n",
    "\n",
    "\n",
    "rule_clusterer = RuleClusterer(\n",
    "    clusterer_getter=lambda n_clusters: SklearnClusterer(KMeans(n_clusters=n_clusters)),\n",
    "    cluster_rule=lambda data: _accuracy(data) < 0.5 and _size(data) >= 10,\n",
    "    stopping_rule=lambda data: _size(data) < 50,\n",
    "    max_depth=7,\n",
    "    branching_factor=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do the rule clustering ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_clusters = rule_clusterer.fit_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display the rule clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster #0\n",
      "accuracy: 0.40 (4/10)\n",
      "prediction: {185: 2, 19: 1, 201: 1, 151: 1, 230: 1, 364: 1, 780: 1, 692: 1, 321: 1}\n",
      "label: {12: 1, 154: 1, 158: 1, 185: 1, 191: 1, 230: 1, 364: 1, 780: 1, 921: 1, 946: 1}\n"
     ]
    }
   ],
   "source": [
    "for displayer in displayers:\n",
    "    displayer(rule_clusters, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
